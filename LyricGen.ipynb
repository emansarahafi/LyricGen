{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c6ea1b",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/emanafi/lyricgen?scriptVersionId=257530258\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfc2cde",
   "metadata": {
    "papermill": {
     "duration": 0.006984,
     "end_time": "2025-08-22T14:54:55.586755",
     "exception": false,
     "start_time": "2025-08-22T14:54:55.579771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**LyricGen - An AI-Powered Lyric Completion Tool**\n",
    "\n",
    "By Eman Sarah Afi\n",
    "\n",
    "_Fall 2024_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc6113",
   "metadata": {
    "papermill": {
     "duration": 0.005892,
     "end_time": "2025-08-22T14:54:55.59778",
     "exception": false,
     "start_time": "2025-08-22T14:54:55.591888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **1. Data Cleaning & Preprocessing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203a4c15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:54:55.609303Z",
     "iopub.status.busy": "2025-08-22T14:54:55.608914Z",
     "iopub.status.idle": "2025-08-22T14:55:16.136111Z",
     "shell.execute_reply": "2025-08-22T14:55:16.135196Z"
    },
    "papermill": {
     "duration": 20.535175,
     "end_time": "2025-08-22T14:55:16.137924",
     "exception": false,
     "start_time": "2025-08-22T14:54:55.602749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, LayerNormalization, Dropout, MultiHeadAttention, Layer, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ffdd257",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-22T14:55:16.15003Z",
     "iopub.status.busy": "2025-08-22T14:55:16.149292Z",
     "iopub.status.idle": "2025-08-22T14:59:20.493505Z",
     "shell.execute_reply": "2025-08-22T14:59:20.492546Z"
    },
    "papermill": {
     "duration": 244.357026,
     "end_time": "2025-08-22T14:59:20.500413",
     "exception": false,
     "start_time": "2025-08-22T14:55:16.143387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               title  tag     artist  year   views  \\\n",
      "0          Killa Cam  rap    Cam'ron  2004  173166   \n",
      "1         Can I Live  rap      JAY-Z  1996  468624   \n",
      "2  Forgive Me Father  rap   Fabolous  2003    4743   \n",
      "3       Down and Out  rap    Cam'ron  2004  144404   \n",
      "4             Fly In  rap  Lil Wayne  2005   78271   \n",
      "5     Lollipop Remix  rap  Lil Wayne  2008  580832   \n",
      "6         Im Not You  rap     Clipse  2002   28645   \n",
      "7        Family Ties  rap    Cam'ron  2004   41960   \n",
      "8  Rockin and Rollin  rap    Cam'ron  1998    6399   \n",
      "9      Lord You Know  rap    Cam'ron  2004   11882   \n",
      "\n",
      "                                       features  \\\n",
      "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
      "1                                            {}   \n",
      "2                                            {}   \n",
      "3  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
      "4                                            {}   \n",
      "5                 {\"Kanye West\",\"Static Major\"}   \n",
      "6   {Jadakiss,\"Styles P\",\"Roscoe P. Coldchain\"}   \n",
      "7                     {\"Cam\\\\'ron\",\"Lady Wray\"}   \n",
      "8                                 {\"Cam\\\\'ron\"}   \n",
      "9          {\"Cam\\\\'ron\",\"Juelz Santana\",Jaheim}   \n",
      "\n",
      "                                              lyrics  id language_cld3  \\\n",
      "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1            en   \n",
      "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3            en   \n",
      "2  Maybe cause I'm eatin\\nAnd these bastards fien...   4            en   \n",
      "3  [Produced by Kanye West and Brian Miller]\\n\\n[...   5            en   \n",
      "4  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6            en   \n",
      "5  [Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...   7            en   \n",
      "6  [Intro: Pusha T]\\nNo, no, no!\\nI told you, I l...   8            en   \n",
      "7  [Verse 1: Cam'ron]\\nKilla, Dipset\\nMan I spit ...   9            en   \n",
      "8  [Verse 1]\\nAy yo you wonder who I are\\nI guzzl...  10            en   \n",
      "9  [Chorus: Jaheim]\\nNow Lord you know, just how ...  11            en   \n",
      "\n",
      "  language_ft language  \n",
      "0          en       en  \n",
      "1          en       en  \n",
      "2          en       en  \n",
      "3          en       en  \n",
      "4          en       en  \n",
      "5          en       en  \n",
      "6          en       en  \n",
      "7          en       en  \n",
      "8          en       en  \n",
      "9          en       en  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5134856 entries, 0 to 5134855\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   title          object\n",
      " 1   tag            object\n",
      " 2   artist         object\n",
      " 3   year           int64 \n",
      " 4   views          int64 \n",
      " 5   features       object\n",
      " 6   lyrics         object\n",
      " 7   id             int64 \n",
      " 8   language_cld3  object\n",
      " 9   language_ft    object\n",
      " 10  language       object\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 430.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('/kaggle/input/genius-song-lyrics-with-language-information/song_lyrics.csv')\n",
    "\n",
    "# Display the first 10 rows of the dataset\n",
    "print(dataset.head(10))\n",
    "\n",
    "# Display dataset info (columns, data-types, non-null counts)\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab8d76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:59:20.511951Z",
     "iopub.status.busy": "2025-08-22T14:59:20.511643Z",
     "iopub.status.idle": "2025-08-22T14:59:22.671676Z",
     "shell.execute_reply": "2025-08-22T14:59:22.670687Z"
    },
    "papermill": {
     "duration": 2.167865,
     "end_time": "2025-08-22T14:59:22.673521",
     "exception": false,
     "start_time": "2025-08-22T14:59:20.505656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title            0.003661\n",
      "tag              0.000000\n",
      "artist           0.000000\n",
      "year             0.000000\n",
      "views            0.000000\n",
      "features         0.000000\n",
      "lyrics           0.000000\n",
      "id               0.000000\n",
      "language_cld3    1.771539\n",
      "language_ft      2.615886\n",
      "language         4.419170\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the percentage of missing values per column\n",
    "print(dataset.isnull().sum() / len(dataset) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99625639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:59:22.685499Z",
     "iopub.status.busy": "2025-08-22T14:59:22.685216Z",
     "iopub.status.idle": "2025-08-22T14:59:24.488729Z",
     "shell.execute_reply": "2025-08-22T14:59:24.487677Z"
    },
    "papermill": {
     "duration": 1.811411,
     "end_time": "2025-08-22T14:59:24.490517",
     "exception": false,
     "start_time": "2025-08-22T14:59:22.679106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of rows with 'en': 65.71%\n",
      "Percentage of rows with 'fr': 3.69%\n",
      "Percentage of rows with 'ar': 0.19%\n"
     ]
    }
   ],
   "source": [
    "# Define target languages (English, French, Arabic)\n",
    "target_languages = ['en', 'fr', 'ar']\n",
    "\n",
    "# Total rows in the dataset\n",
    "total_rows = len(dataset)\n",
    "\n",
    "# Calculate the percentage for each target language\n",
    "percentages = {\n",
    "    lang: (len(dataset[dataset['language'] == lang]) / total_rows) * 100\n",
    "    for lang in target_languages\n",
    "}\n",
    "\n",
    "# Display the percentages\n",
    "for lang, percentage in percentages.items():\n",
    "    print(f\"Percentage of rows with '{lang}': {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac8fcbd",
   "metadata": {
    "papermill": {
     "duration": 0.005347,
     "end_time": "2025-08-22T14:59:24.501635",
     "exception": false,
     "start_time": "2025-08-22T14:59:24.496288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Naturally, considering that the intention is to work with three languages (English, French & Arabic), we have to filter the dataset to include the rows with these languages only. \n",
    "\n",
    "However, considering that the percentage of 'en' is extremely high, which could lead to performance issues on Kaggle, it is recommended to take a sample of rows that have 'en' as the language.\n",
    "\n",
    "Other than that, the text is cleaned by removing punctuation, unique characters, and converting it to lowercase (except for Arabic). Plus, structural tags (e.g., [Chorus: ...]) will be removed to reduce the noise, and repeated lyrics were handled to prevent redundancy in tokenized sequences.\n",
    "\n",
    "Finally, the dataset should only keep the columns it needs for this project, which in this case, the kept columns are 'language' and 'cleaned_lyrics'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a64ebce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:59:24.513747Z",
     "iopub.status.busy": "2025-08-22T14:59:24.512997Z",
     "iopub.status.idle": "2025-08-22T14:59:31.368233Z",
     "shell.execute_reply": "2025-08-22T14:59:31.367321Z"
    },
    "papermill": {
     "duration": 6.863336,
     "end_time": "2025-08-22T14:59:31.370239",
     "exception": false,
     "start_time": "2025-08-22T14:59:24.506903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group sizes before sampling: language\n",
      "en    3374198\n",
      "fr     189436\n",
      "ar       9889\n",
      "Name: count, dtype: int64\n",
      "Final dataset columns: ['language', 'cleaned_lyrics']\n",
      "Number of rows: 27000\n",
      "language\n",
      "en    9000\n",
      "fr    9000\n",
      "ar    9000\n",
      "Name: count, dtype: int64\n",
      "        language                                     cleaned_lyrics\n",
      "2645152       en  dont want to be along anymore dont want to hea...\n",
      "1939177       en  africa rappers fuck you i dey greet so you guy...\n",
      "969631        en  every time i kiss somebody new i make believe ...\n",
      "4041818       en  i am the one who calls your name the day you l...\n",
      "1976310       en  hella sketchy im always glistenin im always gl...\n"
     ]
    }
   ],
   "source": [
    "# Filter dataset using the 'language' column and create an explicit copy\n",
    "filtered_dataset = dataset[dataset['language'].isin(target_languages)].copy()\n",
    "\n",
    "# Function for cleaning multilingual lyrics (removes punctuation)\n",
    "def clean_multilingual_lyrics_simple(lyric, lang):\n",
    "    if pd.isnull(lyric):  # Handle missing lyrics\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove structural tags (e.g., [Chorus: Opera Steve & Cam'ron])\n",
    "    lyric = re.sub(r\"\\[.*?\\]\", \"\", lyric)\n",
    "    \n",
    "    # Handle language-specific cleaning\n",
    "    if lang == 'en':\n",
    "        lyric = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", lyric).lower()\n",
    "    elif lang == 'fr':\n",
    "        lyric = re.sub(r\"[^a-zA-ZÀ-ÿ0-9\\s]\", \"\", lyric).lower()\n",
    "    elif lang == 'ar':\n",
    "        lyric = re.sub(r\"[^\\u0600-\\u06FF0-9\\s]\", \"\", lyric)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    lyric = \" \".join(lyric.split())\n",
    "    return lyric\n",
    "\n",
    "# Inspect group sizes\n",
    "group_sizes = filtered_dataset['language'].value_counts()\n",
    "print(\"Group sizes before sampling:\", group_sizes)\n",
    "\n",
    "# Set target sample size for each language\n",
    "target_sample_size = 9000\n",
    "\n",
    "# Sample data for each language\n",
    "sampled_en = filtered_dataset[filtered_dataset['language'] == 'en'].sample(\n",
    "    n=min(target_sample_size, len(filtered_dataset[filtered_dataset['language'] == 'en'])),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sampled_fr = filtered_dataset[filtered_dataset['language'] == 'fr'].sample(\n",
    "    n=min(target_sample_size, len(filtered_dataset[filtered_dataset['language'] == 'fr'])),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sampled_ar = filtered_dataset[filtered_dataset['language'] == 'ar'].sample(\n",
    "    n=min(target_sample_size, len(filtered_dataset[filtered_dataset['language'] == 'ar'])),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine all sampled data\n",
    "sampled_dataset = pd.concat([sampled_en, sampled_fr, sampled_ar])\n",
    "\n",
    "# Apply the cleaning function to the sampled dataset\n",
    "sampled_dataset = sampled_dataset.assign(\n",
    "    cleaned_lyrics=sampled_dataset.apply(\n",
    "        lambda row: clean_multilingual_lyrics_simple(row['lyrics'], row['language']),\n",
    "        axis=1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Keep only 'language' and 'cleaned_lyrics' columns\n",
    "sampled_dataset = sampled_dataset[['language', 'cleaned_lyrics']]\n",
    "\n",
    "# Display dataset summary\n",
    "print(f\"Final dataset columns: {sampled_dataset.columns.tolist()}\")\n",
    "print(f\"Number of rows: {len(sampled_dataset)}\")\n",
    "print(sampled_dataset['language'].value_counts())\n",
    "print(sampled_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d293ac",
   "metadata": {
    "papermill": {
     "duration": 0.005726,
     "end_time": "2025-08-22T14:59:31.382424",
     "exception": false,
     "start_time": "2025-08-22T14:59:31.376698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After the cleaning phase, it is preferred to check if there are any duplicated rows before proceeding with the embedding & tokenization phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c962fc42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:59:31.395308Z",
     "iopub.status.busy": "2025-08-22T14:59:31.395035Z",
     "iopub.status.idle": "2025-08-22T14:59:31.83784Z",
     "shell.execute_reply": "2025-08-22T14:59:31.836899Z"
    },
    "papermill": {
     "duration": 0.451258,
     "end_time": "2025-08-22T14:59:31.839623",
     "exception": false,
     "start_time": "2025-08-22T14:59:31.388365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of duplicated rows: 0.27%\n",
      "Percentage of duplicated rows: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Number of duplicated rows\n",
    "num_duplicates = sampled_dataset.duplicated().sum()\n",
    "\n",
    "# Percentage of duplicated rows\n",
    "percentage_duplicates = (num_duplicates / len(sampled_dataset)) * 100\n",
    "print(f\"Percentage of duplicated rows: {percentage_duplicates:.2f}%\")\n",
    "\n",
    "final_dataset = sampled_dataset.drop_duplicates()\n",
    "\n",
    "# Number of duplicated rows\n",
    "num_duplicates = final_dataset.duplicated().sum()\n",
    "\n",
    "# Check for duplicated rows again\n",
    "percentage_duplicates = (num_duplicates / len(final_dataset)) * 100\n",
    "print(f\"Percentage of duplicated rows: {percentage_duplicates:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a0b02c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:59:31.852493Z",
     "iopub.status.busy": "2025-08-22T14:59:31.852235Z",
     "iopub.status.idle": "2025-08-22T14:59:31.860108Z",
     "shell.execute_reply": "2025-08-22T14:59:31.859236Z"
    },
    "papermill": {
     "duration": 0.016196,
     "end_time": "2025-08-22T14:59:31.861936",
     "exception": false,
     "start_time": "2025-08-22T14:59:31.84574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language          0.0\n",
      "cleaned_lyrics    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the percentage of missing values per column\n",
    "print(final_dataset.isnull().sum() / len(final_dataset) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4cbb9",
   "metadata": {
    "papermill": {
     "duration": 0.00597,
     "end_time": "2025-08-22T14:59:31.873904",
     "exception": false,
     "start_time": "2025-08-22T14:59:31.867934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **2. Embedding Preparation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050438ca",
   "metadata": {
    "papermill": {
     "duration": 0.005836,
     "end_time": "2025-08-22T14:59:31.885915",
     "exception": false,
     "start_time": "2025-08-22T14:59:31.880079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The purpose of the embedding phase here is to transform text data into numerical representations suitable for Transformer-based models. \n",
    "\n",
    "To explain further:\n",
    "- **max_vocab_size** limits the vocabulary to the most frequent 30,000 words for optimal performance\n",
    "- **max_sequence_length** sets a fixed sequence length of 80 for uniform input size\n",
    "\n",
    "These values were chosen while taking into consideration the complexity of the multilingual and diverse nature of the Genius dataset, as well as memory constraints on Kaggle.\n",
    "\n",
    "**Important Note on Vocabulary Management:**\n",
    "The tokenizer discovers all unique tokens in the dataset but uses only the top 30,000 most frequent tokens during training and generation. This approach:\n",
    "- **Reduces memory usage** by limiting the embedding and output layer sizes\n",
    "- **Improves training stability** by focusing on the most relevant vocabulary\n",
    "- **Prevents out-of-vocabulary issues** during generation by maintaining a consistent vocabulary size\n",
    "\n",
    "Then, tokenization is done for all languages where the cleaned lyrics are converted into sequences of integers, and out-of-vocabulary words are replaced by a special token (`<OOV>`). After that, padding ensures that all sequences have the same length for compatibility reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca227fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:59:31.899383Z",
     "iopub.status.busy": "2025-08-22T14:59:31.898607Z",
     "iopub.status.idle": "2025-08-22T14:59:47.0603Z",
     "shell.execute_reply": "2025-08-22T14:59:47.059169Z"
    },
    "papermill": {
     "duration": 15.170412,
     "end_time": "2025-08-22T14:59:47.062205",
     "exception": false,
     "start_time": "2025-08-22T14:59:31.891793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a unified tokenizer on all languages...\n",
      "Tokenizer fitting complete.\n",
      "Using configured vocabulary size: 30000\n",
      "Full discovered vocabulary size: 510228\n",
      "Note: Tokenizer discovered 510228 unique tokens,\n",
      "but will use only the top 30000 most frequent tokens.\n",
      "Converting texts to sequences...\n",
      "Padding complete.\n",
      "\n",
      "Total padded sequences: 26928\n",
      "Training samples: 21542\n",
      "Validation samples: 2693\n",
      "Test samples: 2693\n",
      "\n",
      "Example processed sequence (from X_train): \n",
      "[   30    36    66    50    51    19 25389  8735    66    50    51    19\n",
      " 23022  8735    59  6311    10   113   850    66    50    51    19 25389\n",
      "  8735    66    50    51    19 23022  8735    59  6311    10   113   850\n",
      "     5    90   367    10   947   165     2  3991   944  2444    23     7\n",
      "  3991    27  1077   388  2348  9781  4833    52  1954     7  1115    52\n",
      "    51  2833   170     1   571   211   301  1502     1  4994   200     3\n",
      "   146   414    90   239 18122   706    57   192]\n",
      "\n",
      "Data is now correctly prepared for the decoder-only transformer.\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "max_vocab_size = 30000\n",
    "max_sequence_length = 80\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "# 1. Create a single, unified tokenizer for all languages\n",
    "tokenizer = Tokenizer(num_words=max_vocab_size, oov_token=\"<OOV>\")\n",
    "\n",
    "# 2. Prepare all texts with special tokens, INCLUDING a language token\n",
    "all_lyrics_with_lang = final_dataset[['cleaned_lyrics', 'language']].astype(str).values.tolist()\n",
    "texts_with_tokens = [f\"<{lang}> {sos_token} {text} {eos_token}\" for text, lang in all_lyrics_with_lang]\n",
    "\n",
    "# 3. Fit the single tokenizer on all available text data\n",
    "print(\"Fitting a unified tokenizer on all languages...\")\n",
    "tokenizer.fit_on_texts(texts_with_tokens)\n",
    "print(\"Tokenizer fitting complete.\")\n",
    "\n",
    "# 4. Use the configured max vocabulary size (not the full discovered size)\n",
    "vocab_size = max_vocab_size\n",
    "print(f\"Using configured vocabulary size: {vocab_size}\")\n",
    "print(f\"Full discovered vocabulary size: {len(tokenizer.word_index) + 1}\")\n",
    "\n",
    "# Verify that our tokenizer will respect the num_words limit\n",
    "if len(tokenizer.word_index) + 1 > max_vocab_size:\n",
    "    print(f\"Note: Tokenizer discovered {len(tokenizer.word_index) + 1} unique tokens,\")\n",
    "    print(f\"but will use only the top {max_vocab_size} most frequent tokens.\")\n",
    "else:\n",
    "    print(f\"All discovered tokens ({len(tokenizer.word_index) + 1}) fit within the limit.\")\n",
    "\n",
    "# 5. Convert all texts to integer sequences\n",
    "print(\"Converting texts to sequences...\")\n",
    "sequences = tokenizer.texts_to_sequences(texts_with_tokens)\n",
    "\n",
    "# 6. Pad all sequences to the same fixed length\n",
    "X_padded = pad_sequences(\n",
    "    sequences, \n",
    "    maxlen=max_sequence_length, \n",
    "    padding='post', \n",
    "    truncating='post',\n",
    "    dtype='int32'\n",
    ")\n",
    "print(\"Padding complete.\")\n",
    "\n",
    "# 7. Split the single dataset into training, validation, and test sets\n",
    "X_train, X_temp = train_test_split(X_padded, test_size=0.2, random_state=42)\n",
    "X_val, X_test = train_test_split(X_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Final Summaries\n",
    "print(f\"\\nTotal padded sequences: {len(X_padded)}\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "\n",
    "# Example data\n",
    "print(f\"\\nExample processed sequence (from X_train): \\n{X_train[0]}\")\n",
    "print(\"\\nData is now correctly prepared for the decoder-only transformer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa752446",
   "metadata": {
    "papermill": {
     "duration": 0.006187,
     "end_time": "2025-08-22T14:59:47.074779",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.068592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **3. Output Readiness Check:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca8219",
   "metadata": {
    "papermill": {
     "duration": 0.005712,
     "end_time": "2025-08-22T14:59:47.086473",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.080761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code segment will simply check if:\n",
    "- The output shape is a 2D array for Transformer input.\n",
    "- The sequences are of type int32 to ensure compatibility with embedding layers.\n",
    "- Labels are included and match the number of sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23de6760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:59:47.099456Z",
     "iopub.status.busy": "2025-08-22T14:59:47.098703Z",
     "iopub.status.idle": "2025-08-22T14:59:47.107042Z",
     "shell.execute_reply": "2025-08-22T14:59:47.106132Z"
    },
    "papermill": {
     "duration": 0.016534,
     "end_time": "2025-08-22T14:59:47.108738",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.092204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the full dataset (X_padded): (26928, 80)\n",
      "Shape of the training set (X_train): (21542, 80)\n",
      "Data type of padded sequences (X_padded): int32\n",
      "\n",
      "Maximum token ID found in the dataset: 29999\n",
      "Tokenizer vocabulary size (len(word_index) + 1): 30000\n",
      "Token IDs are all within the vocabulary range.\n",
      "\n",
      "--- Example of how data is fed to the model ---\n",
      "Original sequence (from X_train[0]): [   30    36    66    50    51    19 25389  8735    66    50    51    19\n",
      " 23022  8735    59  6311    10   113   850    66    50    51    19 25389\n",
      "  8735    66    50    51    19 23022  8735    59  6311    10   113   850\n",
      "     5    90   367    10   947   165     2  3991   944  2444    23     7\n",
      "  3991    27  1077   388  2348  9781  4833    52  1954     7  1115    52\n",
      "    51  2833   170     1   571   211   301  1502     1  4994   200     3\n",
      "   146   414    90   239 18122   706    57   192]\n",
      "Model Input (sequence[:-1]):         [   30    36    66    50    51    19 25389  8735    66    50    51    19\n",
      " 23022  8735    59  6311    10   113   850    66    50    51    19 25389\n",
      "  8735    66    50    51    19 23022  8735    59  6311    10   113   850\n",
      "     5    90   367    10   947   165     2  3991   944  2444    23     7\n",
      "  3991    27  1077   388  2348  9781  4833    52  1954     7  1115    52\n",
      "    51  2833   170     1   571   211   301  1502     1  4994   200     3\n",
      "   146   414    90   239 18122   706    57]\n",
      "Model Target (sequence[1:]):          [   36    66    50    51    19 25389  8735    66    50    51    19 23022\n",
      "  8735    59  6311    10   113   850    66    50    51    19 25389  8735\n",
      "    66    50    51    19 23022  8735    59  6311    10   113   850     5\n",
      "    90   367    10   947   165     2  3991   944  2444    23     7  3991\n",
      "    27  1077   388  2348  9781  4833    52  1954     7  1115    52    51\n",
      "  2833   170     1   571   211   301  1502     1  4994   200     3   146\n",
      "   414    90   239 18122   706    57   192]\n",
      "\n",
      "\n",
      "Processed data is ready for the Transformer model.\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the full padded dataset\n",
    "print(f\"Shape of the full dataset (X_padded): {X_padded.shape}\")\n",
    "assert len(X_padded.shape) == 2, \"Padded data should be 2D (num_samples, max_sequence_length).\"\n",
    "\n",
    "# Check the shape of the training set as a representative sample\n",
    "print(f\"Shape of the training set (X_train): {X_train.shape}\")\n",
    "assert len(X_train.shape) == 2, \"Training data should be 2D (num_samples, max_sequence_length).\"\n",
    "\n",
    "# Check the data type of the sequences\n",
    "print(f\"Data type of padded sequences (X_padded): {X_padded.dtype}\")\n",
    "assert X_padded.dtype == 'int32', \"Padded sequences should be of type int32 for embedding layers.\"\n",
    "\n",
    "# Validate the vocabulary size against the maximum token ID in the dataset\n",
    "max_token_id = np.max(X_padded)\n",
    "print(f\"\\nMaximum token ID found in the dataset: {max_token_id}\")\n",
    "print(f\"Tokenizer vocabulary size (len(word_index) + 1): {vocab_size}\")\n",
    "assert max_token_id < vocab_size, f\"A token ID ({max_token_id}) exceeds the vocabulary size ({vocab_size}).\"\n",
    "print(\"Token IDs are all within the vocabulary range.\")\n",
    "\n",
    "# Demonstrate how a single sequence is split into an input/target pair for the model\n",
    "example_input_for_model = X_train[0, :-1]\n",
    "example_target_for_model = X_train[0, 1:]\n",
    "\n",
    "print(\"\\n--- Example of how data is fed to the model ---\")\n",
    "print(\"Original sequence (from X_train[0]):\", X_train[0])\n",
    "print(\"Model Input (sequence[:-1]):        \", example_input_for_model)\n",
    "print(\"Model Target (sequence[1:]):         \", example_target_for_model)\n",
    "\n",
    "print(\"\\n\\nProcessed data is ready for the Transformer model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dcc5f7",
   "metadata": {
    "papermill": {
     "duration": 0.005859,
     "end_time": "2025-08-22T14:59:47.120449",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.11459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **4. Transformer Architecture:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423737c3",
   "metadata": {
    "papermill": {
     "duration": 0.005659,
     "end_time": "2025-08-22T14:59:47.132207",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.126548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code defines a custom and highly flexible TensorFlow layer called `PositionalEncoding`. Its purpose is to inject information about the position of each token into the sequence embeddings, which is crucial for Transformer models that do not otherwise have an inherent sense of order.\n",
    "\n",
    "This updated version is designed to be robust for generative tasks by creating the encoding **dynamically** for any given sequence length.\n",
    "\n",
    "#### 1. `__init__` method:\n",
    "\n",
    "Initializes the layer. It is very lightweight and only requires the `embed_dim` (the embedding dimension of the model) to be stored for use during the forward pass. Unlike previous static versions, it does **not** pre-compute a fixed-size encoding matrix.\n",
    "\n",
    "#### 2. `call` method:\n",
    "\n",
    "This method defines the forward pass of the layer and is where the positional encoding is generated \"on-the-fly\" for each input batch.\n",
    "\n",
    "*   **1. Dynamic Shape Detection:** It first determines the `sequence_length` directly from the input tensor it receives. This is the key to its flexibility, as it works for any length.\n",
    "*   **2. Angle Calculation:** It calculates the positional encoding angles using the standard Transformer formula. It creates a tensor of positions (from 0 to `sequence_length - 1`) and combines it with a term based on the embedding dimension.\n",
    "*   **3. Sine and Cosine Application:** It applies the `sin` function to even indices of the embedding dimension and the `cos` function to the odd indices, creating the final encoding signals.\n",
    "*   **4. Addition to Input:** Finally, it adds this newly generated positional encoding matrix directly to the original input token embeddings.\n",
    "\n",
    "The key advantage of this dynamic approach is its ability to handle sequences of varying lengths. This is essential during auto-regressive generation (where the input sequence grows by one token at each step), ensuring the model can be trained on fixed-length sequences but used for generation on variable-length ones without encountering shape-mismatch errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f048f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:59:47.144955Z",
     "iopub.status.busy": "2025-08-22T14:59:47.144721Z",
     "iopub.status.idle": "2025-08-22T14:59:47.151516Z",
     "shell.execute_reply": "2025-08-22T14:59:47.150727Z"
    },
    "papermill": {
     "duration": 0.015177,
     "end_time": "2025-08-22T14:59:47.15322",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.138043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        This version computes the positional encoding dynamically based on the\n",
    "        input sequence length, making it flexible for generation.\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        \n",
    "        position = tf.range(start=0, limit=seq_len, delta=1, dtype=tf.float32)\n",
    "        \n",
    "        div_term = tf.pow(10000.0, (2.0 * tf.range(0, self.embed_dim, 2, dtype=tf.float32)) / float(self.embed_dim))\n",
    "        \n",
    "        position = position[:, tf.newaxis]\n",
    "        div_term = div_term[tf.newaxis, :]\n",
    "        \n",
    "        angle_rads = position / div_term\n",
    "        \n",
    "        sin_part = tf.sin(angle_rads)\n",
    "        cos_part = tf.cos(angle_rads)\n",
    "        \n",
    "        # Interleave sin and cos parts\n",
    "        encoding = tf.reshape(tf.stack([sin_part, cos_part], axis=-1), [seq_len, self.embed_dim])\n",
    "        \n",
    "        encoding = encoding[tf.newaxis, :, :]\n",
    "        \n",
    "        return inputs + encoding\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"embed_dim\": self.embed_dim})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8878ba4f",
   "metadata": {
    "papermill": {
     "duration": 0.005877,
     "end_time": "2025-08-22T14:59:47.165453",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.159576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code defines a `TransformerDecoderBlock` as a custom Keras `Layer`. This block is the fundamental building block of a **Decoder-Only (GPT-style) Transformer**. Unlike a standard Transformer decoder, it does not have a second attention layer for cross-attention with an encoder, as there is no encoder in this architecture.\n",
    "\n",
    "Its main purpose is to take a sequence of token embeddings and enrich them with contextual information from preceding tokens in the sequence.\n",
    "\n",
    "Here's a breakdown of its components:\n",
    "\n",
    "#### Sub-layer 1: Masked Multi-Head Self-Attention\n",
    "\n",
    "*   **Purpose:** This is the core of the block. It allows each token in the sequence to look at and gather information from all the *previous* tokens in the same sequence.\n",
    "*   **Causal Mask:** A crucial \"causal mask\" is applied during this step. This mask prevents any token from \"cheating\" by attending to future tokens. For example, when predicting the 5th word, the model can only see words 1 through 4. This is essential for a generative model that predicts one word at a time.\n",
    "*   **Process:** The output of the attention mechanism is passed through a `Dropout` layer for regularization, and then combined with the original input via a residual connection (`Add`) and normalized with `LayerNormalization`.\n",
    "\n",
    "#### Sub-layer 2: Position-wise Feed-Forward Network (FFN)\n",
    "\n",
    "*   **Purpose:** This is a standard two-layer fully connected neural network that is applied independently to each position in the sequence. It provides additional learning capacity and transforms the representations learned by the attention layer.\n",
    "*   **Structure:** It consists of two `Dense` layers, with a ReLU activation function in between.\n",
    "*   **Process:** Similar to the first sub-layer, the FFN's output is regularized with `Dropout`, combined with the input from the previous step (the output of the first sub-layer) via a residual connection, and finally normalized.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Input and Output:**\n",
    "\n",
    "*   **Input:** The block takes a single tensor `inputs` with a shape of `(batch_size, sequence_length, embed_dim)`.\n",
    "*   **Output:** It returns a tensor of the **exact same shape** `(batch_size, sequence_length, embed_dim)`, which can then be passed to the next `TransformerDecoderBlock` in the stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf2fbc23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:59:47.179183Z",
     "iopub.status.busy": "2025-08-22T14:59:47.178538Z",
     "iopub.status.idle": "2025-08-22T14:59:47.187521Z",
     "shell.execute_reply": "2025-08-22T14:59:47.186903Z"
    },
    "papermill": {
     "duration": 0.017478,
     "end_time": "2025-08-22T14:59:47.189033",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.171555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoderBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "        self.add1 = Add()\n",
    "        self.add2 = Add()\n",
    "\n",
    "    def create_causal_mask(self, size):\n",
    "        # Creates a boolean mask to prevent attention to future tokens.\n",
    "        mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "        return mask[tf.newaxis, tf.newaxis, :, :] # (1, 1, size, size)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        seq_len = input_shape[1]\n",
    "        \n",
    "        # 1. Create the causal mask dynamically\n",
    "        causal_mask = self.create_causal_mask(seq_len)\n",
    "\n",
    "        # 2. Masked Multi-Head Self-Attention\n",
    "        attention_output = self.mha(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask, training=training\n",
    "        )\n",
    "        attention_output = self.dropout1(attention_output, training=training)\n",
    "        out1 = self.layernorm1(self.add1([inputs, attention_output]))\n",
    "\n",
    "        # 3. Feed-Forward Network\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(self.add2([out1, ffn_output]))\n",
    "        \n",
    "        return out2\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"dropout_rate\": self.dropout_rate\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "353c672f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:59:47.201578Z",
     "iopub.status.busy": "2025-08-22T14:59:47.201153Z",
     "iopub.status.idle": "2025-08-22T14:59:47.206193Z",
     "shell.execute_reply": "2025-08-22T14:59:47.205381Z"
    },
    "papermill": {
     "duration": 0.012964,
     "end_time": "2025-08-22T14:59:47.207748",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.194784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The main function to build the complete Decoder-Only Transformer\n",
    "def build_decoder_only_transformer(vocab_size, embed_dim, num_heads, ff_dim, num_decoder_layers, dropout_rate):\n",
    "    inputs = Input(shape=(None,), dtype=\"int32\", name=\"Input_Layer\")\n",
    "    \n",
    "    # Embedding and Positional Encoding\n",
    "    x = Embedding(vocab_size, embed_dim, name=\"Embedding_Layer\")(inputs)\n",
    "    x = PositionalEncoding(embed_dim)(x) \n",
    "    \n",
    "    # Stack of Decoder Blocks\n",
    "    for i in range(num_decoder_layers):\n",
    "        x = TransformerDecoderBlock(embed_dim, num_heads, ff_dim, dropout_rate, name=f\"decoder_block_{i}\")(x)\n",
    "\n",
    "    # Final Output Layer\n",
    "    outputs = Dense(vocab_size, activation=\"softmax\", name=\"Output_Layer\")(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"Decoder_Only_Transformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d779e",
   "metadata": {
    "papermill": {
     "duration": 0.005605,
     "end_time": "2025-08-22T14:59:47.218953",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.213348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **5. Training & Validation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb38da",
   "metadata": {
    "papermill": {
     "duration": 0.005502,
     "end_time": "2025-08-22T14:59:47.230176",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.224674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code segment orchestrates the training and evaluation of the **Decoder-Only (GPT-style) Transformer**. The model's objective is to function as a generative language model, learning to predict the next word in a sequence given the preceding words.\n",
    "\n",
    "Here's a breakdown of each key step:\n",
    "\n",
    "#### **Hyperparameter Configuration**\n",
    "\n",
    "These parameters define the model's architecture and the training process. They have been optimized to balance performance with the memory constraints of the GPU environment.\n",
    "\n",
    "*   **`embed_dim` (256):** The size of the dense vector representation for each word/token.\n",
    "*   **`num_heads` (4):** The number of attention heads in the multi-head attention mechanism. Reduced to save memory.\n",
    "*   **`ff_dim` (2048):** The dimensionality of the inner layer of the feed-forward networks.\n",
    "*   **`num_decoder_layers` (4):** The number of `TransformerDecoderBlock` layers stacked on top of each other. A shallower model is used to conserve memory.\n",
    "*   **`dropout_rate` (0.1):** The fraction of units to drop during training to prevent overfitting.\n",
    "*   **`vocab_size` (30,000):** **CRITICAL:** Uses the configured vocabulary size limit for optimal model architecture. This ensures:\n",
    "    - **Consistent model dimensions** across different datasets\n",
    "    - **Predictable memory usage** for reliable training on Kaggle\n",
    "    - **Optimal generation performance** with proper vocabulary management\n",
    "*   **`max_len`:** The maximum sequence length for padding.\n",
    "*   **`batch_size` (8):** The number of sequences processed in each training step. Kept small to manage GPU memory.\n",
    "*   **`epochs` (60):** The *maximum* number of times the model will iterate over the entire training dataset.\n",
    "*   **`learning_rate` (1e-4):** The step size for the optimizer.\n",
    "\n",
    "#### **Model Building and Compilation**\n",
    "\n",
    "1.  **Build Transformer:** The `build_decoder_only_transformer` function constructs the Keras model using the **optimized 30K vocabulary size** for efficient architecture.\n",
    "2.  **Compile Model:** The model is prepared for training using:\n",
    "    *   **Optimizer:** `AdamW`, a modern and robust variant of the Adam optimizer.\n",
    "    *   **Loss Function:** `sparse_categorical_crossentropy`, standard for next-token prediction tasks.\n",
    "    *   **Metrics:** `accuracy` tracks performance during training.\n",
    "3.  **Summary:** Shows the model architecture with the optimized vocabulary-dependent layer sizes.\n",
    "\n",
    "#### **Data Preparation for Generative Training**\n",
    "\n",
    "The core task is next-word prediction achieved by sequence shifting:\n",
    "*   **Model Input (`X_train_in`):** A sequence excluding its last token (e.g., `<lang> <sos> i love to write`)\n",
    "*   **Model Target (`y_train_out`):** The same sequence excluding its first token (e.g., `<sos> i love to write <eos>`)\n",
    "\n",
    "The model learns to produce the target when given the corresponding input.\n",
    "\n",
    "#### **Dataset Pipelines**\n",
    "Prepared data arrays are converted into efficient `tf.data.Dataset` pipelines for optimal GPU utilization.\n",
    "\n",
    "#### **Callbacks for Intelligent Training**\n",
    "\n",
    "*   **`ModelCheckpoint`:** Saves the best model based on validation loss improvement\n",
    "*   **`EarlyStopping`:** Prevents overfitting by stopping when validation loss plateaus (patience=5)\n",
    "\n",
    "#### **Model Training and Evaluation**\n",
    "\n",
    "1.  **Training:** Uses the prepared datasets with intelligent callbacks\n",
    "2.  **Load Best Model:** Automatically loads the best-performing checkpoint\n",
    "3.  **Test Set Evaluation:** Provides unbiased performance metrics on unseen data\n",
    "\n",
    "#### **Expected Performance with 30K Vocabulary**\n",
    "With the optimized 30K vocabulary size:\n",
    "- **Efficient training** due to focused model architecture\n",
    "- **Optimal memory usage** for Kaggle's GPU environment\n",
    "- **Quality lyrics generation** across multiple languages\n",
    "- **Stable convergence** with concentrated vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beb09c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T14:59:47.242962Z",
     "iopub.status.busy": "2025-08-22T14:59:47.242683Z",
     "iopub.status.idle": "2025-08-22T15:39:41.419945Z",
     "shell.execute_reply": "2025-08-22T15:39:41.419048Z"
    },
    "papermill": {
     "duration": 2394.186231,
     "end_time": "2025-08-22T15:39:41.422089",
     "exception": false,
     "start_time": "2025-08-22T14:59:47.235858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with memory-optimized hyperparameters...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Decoder_Only_Transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Decoder_Only_Transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Embedding_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_encoding             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_0                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,808</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_1                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,808</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_2                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,808</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_3                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,808</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30000</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,710,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input_Layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Embedding_Layer (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m7,680,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_encoding             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_0                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m2,103,808\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_1                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m2,103,808\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_2                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m2,103,808\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_3                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m2,103,808\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30000\u001b[0m)    │     \u001b[38;5;34m7,710,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,805,232</span> (90.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,805,232\u001b[0m (90.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,805,232</span> (90.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,805,232\u001b[0m (90.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755874801.121547      67 service.cc:145] XLA service 0x78df200020d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755874801.121604      67 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1755874801.121608      67 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "W0000 00:00:1755874802.348175      67 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755874812.021172      96 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_171', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755874815.686100      97 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_163', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755874816.744090      96 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_171', 36 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755874817.402348      98 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_171', 1764 bytes spill stores, 1764 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   3/2693\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 43ms/step - accuracy: 0.0718 - loss: 10.2424       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755874826.068388      67 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2148/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.1746 - loss: 6.9527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1755874884.716414      67 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1755874891.837052     124 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_171', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755874898.046399     125 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_171', 1764 bytes spill stores, 1768 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755874898.412886     124 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_163', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2692/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1899 - loss: 6.6669"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1755874923.726716      69 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1755874927.624484      69 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1755874931.631453     160 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_30', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 40ms/step - accuracy: 0.1900 - loss: 6.6660 - val_accuracy: 0.4525 - val_loss: 3.6752\n",
      "Epoch 2/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.4830 - loss: 3.3677 - val_accuracy: 0.5776 - val_loss: 2.5825\n",
      "Epoch 3/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.5798 - loss: 2.4738 - val_accuracy: 0.6608 - val_loss: 2.0096\n",
      "Epoch 4/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.6718 - loss: 1.9046 - val_accuracy: 0.7403 - val_loss: 1.5062\n",
      "Epoch 5/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.7417 - loss: 1.4426 - val_accuracy: 0.8133 - val_loss: 1.1387\n",
      "Epoch 6/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.8076 - loss: 1.0807 - val_accuracy: 0.8389 - val_loss: 0.9300\n",
      "Epoch 7/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.8439 - loss: 0.8503 - val_accuracy: 0.8684 - val_loss: 0.7556\n",
      "Epoch 8/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.8723 - loss: 0.6816 - val_accuracy: 0.8754 - val_loss: 0.6775\n",
      "Epoch 9/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9001 - loss: 0.5403 - val_accuracy: 0.9157 - val_loss: 0.5100\n",
      "Epoch 10/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9253 - loss: 0.4173 - val_accuracy: 0.9278 - val_loss: 0.4450\n",
      "Epoch 11/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9400 - loss: 0.3370 - val_accuracy: 0.9399 - val_loss: 0.3782\n",
      "Epoch 12/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9535 - loss: 0.2701 - val_accuracy: 0.9462 - val_loss: 0.3432\n",
      "Epoch 13/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9661 - loss: 0.2121 - val_accuracy: 0.9597 - val_loss: 0.2809\n",
      "Epoch 14/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9746 - loss: 0.1694 - val_accuracy: 0.9681 - val_loss: 0.2406\n",
      "Epoch 15/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9802 - loss: 0.1397 - val_accuracy: 0.9717 - val_loss: 0.2231\n",
      "Epoch 16/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9842 - loss: 0.1176 - val_accuracy: 0.9741 - val_loss: 0.2059\n",
      "Epoch 17/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9855 - loss: 0.1062 - val_accuracy: 0.9740 - val_loss: 0.2052\n",
      "Epoch 18/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9866 - loss: 0.0973 - val_accuracy: 0.9759 - val_loss: 0.1916\n",
      "Epoch 19/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9873 - loss: 0.0910 - val_accuracy: 0.9780 - val_loss: 0.1853\n",
      "Epoch 20/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 30ms/step - accuracy: 0.9873 - loss: 0.0892 - val_accuracy: 0.9768 - val_loss: 0.1915\n",
      "Epoch 21/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 30ms/step - accuracy: 0.9872 - loss: 0.0865 - val_accuracy: 0.9776 - val_loss: 0.1861\n",
      "Epoch 22/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 30ms/step - accuracy: 0.9872 - loss: 0.0843 - val_accuracy: 0.9773 - val_loss: 0.1869\n",
      "Epoch 23/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 31ms/step - accuracy: 0.9868 - loss: 0.0840 - val_accuracy: 0.9783 - val_loss: 0.1851\n",
      "Epoch 24/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 30ms/step - accuracy: 0.9866 - loss: 0.0822 - val_accuracy: 0.9759 - val_loss: 0.1971\n",
      "Epoch 25/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 30ms/step - accuracy: 0.9868 - loss: 0.0791 - val_accuracy: 0.9777 - val_loss: 0.1883\n",
      "Epoch 26/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 30ms/step - accuracy: 0.9872 - loss: 0.0751 - val_accuracy: 0.9763 - val_loss: 0.1947\n",
      "Epoch 27/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 30ms/step - accuracy: 0.9866 - loss: 0.0747 - val_accuracy: 0.9772 - val_loss: 0.1924\n",
      "Epoch 28/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 30ms/step - accuracy: 0.9861 - loss: 0.0754 - val_accuracy: 0.9766 - val_loss: 0.1915\n",
      "Epoch 28: early stopping\n",
      "\n",
      "Loading best model from checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'decoder_block_0', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'decoder_block_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'decoder_block_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'decoder_block_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1755877176.208012      69 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m332/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9800 - loss: 0.1608"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1755877180.163530      67 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9800 - loss: 0.1610\n",
      "Test Loss: 0.1740\n",
      "Test Accuracy: 0.9791\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Reduce Batch Size (Most Important)\n",
    "batch_size = 8\n",
    "\n",
    "# 2. Simplify the Model Architecture\n",
    "num_decoder_layers = 4\n",
    "num_heads = 4\n",
    "\n",
    "# 3. Other hyperparameters\n",
    "embed_dim = 256\n",
    "ff_dim = 2048\n",
    "dropout_rate = 0.1\n",
    "max_len = max_sequence_length\n",
    "epochs = 60\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Build the new Decoder-Only model with the adjusted parameters\n",
    "print(\"Building model with memory-optimized hyperparameters...\")\n",
    "transformer = build_decoder_only_transformer(\n",
    "    vocab_size,\n",
    "    embed_dim, \n",
    "    num_heads, \n",
    "    ff_dim, \n",
    "    num_decoder_layers, \n",
    "    dropout_rate\n",
    ")\n",
    "\n",
    "# Compile the model using a modern, efficient optimizer\n",
    "transformer.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=learning_rate),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "transformer.summary()\n",
    "\n",
    "# --- Prepare the data for a generative model ---\n",
    "X_train_in = X_train[:, :-1]\n",
    "y_train_out = X_train[:, 1:]\n",
    "\n",
    "X_val_in = X_val[:, :-1]\n",
    "y_val_out = X_val[:, 1:]\n",
    "\n",
    "X_test_in = X_test[:, :-1]\n",
    "y_test_out = X_test[:, 1:]\n",
    "\n",
    "# --- Create Dataset Pipelines ---\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_in, y_train_out)).batch(batch_size).prefetch(tf.data.AUTOTUNE).shuffle(10000)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_in, y_val_out)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_in, y_test_out)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Add Callbacks for better training\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the Transformer\n",
    "history = transformer.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Load the best model before evaluation\n",
    "print(\"\\nLoading best model from checkpoint...\")\n",
    "transformer = tf.keras.models.load_model(\"best_model.keras\", custom_objects={\n",
    "    \"TransformerDecoderBlock\": TransformerDecoderBlock,\n",
    "    \"PositionalEncoding\": PositionalEncoding\n",
    "})\n",
    "\n",
    "# Evaluate the Model on the Test Set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_loss, test_accuracy = transformer.evaluate(test_dataset, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcda91c",
   "metadata": {
    "papermill": {
     "duration": 1.878017,
     "end_time": "2025-08-22T15:39:45.2828",
     "exception": false,
     "start_time": "2025-08-22T15:39:43.404783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **6. Lyrics Generation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4eb20a",
   "metadata": {
    "papermill": {
     "duration": 1.928927,
     "end_time": "2025-08-22T15:39:49.152846",
     "exception": false,
     "start_time": "2025-08-22T15:39:47.223919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Model Configuration Overview**\n",
    "\n",
    "**The model uses a 30K token vocabulary optimized for multilingual lyrics generation.**\n",
    "\n",
    "### **Model Architecture:**\n",
    "\n",
    "1. **Vocabulary Size**: 30,000 tokens for optimal performance and memory efficiency\n",
    "2. **Model Dimensions**: Embedding and output layers sized for 30K vocabulary\n",
    "3. **Generation Strategy**: Produces coherent text across English, French, and Arabic\n",
    "\n",
    "### **Training Process:**\n",
    "\n",
    "1. **Data Preparation**: Tokenization with 30K vocabulary limit\n",
    "2. **Model Training**: Decoder-only transformer architecture\n",
    "3. **Validation**: Test generation across multiple languages\n",
    "\n",
    "### **Model Benefits:**\n",
    "\n",
    "- ⚡ **Efficient Training**: Optimized vocabulary size for faster convergence\n",
    "- 💾 **Memory Optimized**: Fits within Kaggle's GPU memory constraints\n",
    "- 🎵 **Quality Generation**: Produces coherent lyrics in target languages\n",
    "- 🌍 **Multilingual Support**: Consistent performance across English, French, and Arabic\n",
    "\n",
    "**This configuration provides an optimal balance between performance and resource usage.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b98d38",
   "metadata": {
    "papermill": {
     "duration": 1.94167,
     "end_time": "2025-08-22T15:39:52.996509",
     "exception": false,
     "start_time": "2025-08-22T15:39:51.054839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Comprehensive Lyrics Completion System**\n",
    "\n",
    "This implementation provides a production-ready lyrics completion system designed for reliable operation on Kaggle.\n",
    "\n",
    "### **System Architecture**\n",
    "\n",
    "The lyrics completion system implements several key components:\n",
    "\n",
    "1. **Vocabulary Management**: Consistent 30,000 token vocabulary across training and generation\n",
    "2. **Generation Strategies**: Both deterministic (greedy) and probabilistic (temperature-based) completion\n",
    "3. **Multilingual Support**: Seamless operation across English, French, and Arabic lyrics  \n",
    "4. **Error Handling**: Graceful management of edge cases and invalid inputs\n",
    "5. **Debug Capabilities**: Comprehensive logging for monitoring and optimization\n",
    "6. **Production Optimization**: Designed for reliable operation in Kaggle environment\n",
    "\n",
    "### **Technical Features**\n",
    "\n",
    "- **Vocabulary Boundary Management**: Ensures generated tokens stay within vocabulary limits\n",
    "- **Sequence Positioning**: Proper handling of token positions during generation\n",
    "- **Comprehensive Validation**: Input verification at each generation step\n",
    "- **Memory Efficiency**: Optimized model size (30K vocabulary) for faster processing\n",
    "\n",
    "### **Usage Workflow**\n",
    "\n",
    "1. **🧪 Diagnostic Testing**: Run `simple_test()` to verify system functionality\n",
    "2. **🎵 Demo Generation**: Use `demonstrate_lyric_completion()` to see multilingual results\n",
    "3. **🎨 Custom Usage**: Call `complete_lyrics()` directly for specific applications\n",
    "\n",
    "### **Expected Performance**\n",
    "\n",
    "✅ **Coherent text generation** with contextually appropriate lyrics  \n",
    "✅ **Language-specific completions** that maintain linguistic consistency  \n",
    "✅ **Efficient processing** with optimized memory usage  \n",
    "✅ **Reliable operation** across different input types  \n",
    "\n",
    "This system transforms partial lyrics into complete verses by leveraging patterns learned during training, making it suitable for creative applications, music composition assistance, and multilingual lyric generation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68700aa6",
   "metadata": {
    "papermill": {
     "duration": 1.976158,
     "end_time": "2025-08-22T15:39:56.867674",
     "exception": false,
     "start_time": "2025-08-22T15:39:54.891516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code segment demonstrates how to use the trained Decoder-Only Transformer to perform its primary function: **intelligent lyric completion**. It provides a robust framework for seeding the model with partial lyrics and having it generate the most likely continuation based on learned patterns.\n",
    "\n",
    "#### **1. `get_seed_lyrics` Function**\n",
    "\n",
    "*   **Purpose:** To safely extract a short, random phrase from the dataset to use as a seed prompt for completion.\n",
    "*   **Enhanced Features:**\n",
    "    - **Error Handling:** Checks for empty datasets and invalid lyrics\n",
    "    - **Data Validation:** Filters out empty or null lyrics before sampling\n",
    "    - **Debug Output:** Provides detailed logging to track seed selection process\n",
    "*   **Steps:**\n",
    "    1.  Filters the `final_dataset` to get all lyrics for a specified `language`\n",
    "    2.  Validates that non-empty lyrics exist for the language\n",
    "    3.  Randomly selects a valid lyric and extracts the first few words\n",
    "    4.  Returns a clean seed prompt with debugging information\n",
    "*   **Returns:** A string containing the seed prompt (e.g., \"i love to sing\") or empty string if no valid data found\n",
    "\n",
    "#### **2. `complete_lyrics` Function**\n",
    "\n",
    "*   **Purpose:** This is the core completion engine that generates the most likely continuation of partial lyrics using the trained transformer model.\n",
    "*   **Key Improvements:**\n",
    "    - **Robust Input Handling:** Proper sequence padding and shape management\n",
    "    - **Debug Mode:** Comprehensive logging of the generation process\n",
    "    - **Multiple Decoding Strategies:** Both greedy (most likely) and temperature-based sampling\n",
    "    - **Error Recovery:** Graceful handling of generation failures\n",
    "*   **Steps (Auto-regressive Decoding):**\n",
    "    1.  Tokenizes the seed text and validates the input\n",
    "    2.  Iteratively generates tokens using the transformer model\n",
    "    3.  For each step:\n",
    "        *   Pads the current sequence to match expected model input shape\n",
    "        *   Gets probability distribution for the next token\n",
    "        *   Selects next token using either greedy decoding or temperature sampling\n",
    "        *   Stops generation when reaching end token or maximum length\n",
    "    4.  Converts the token sequence back to readable text\n",
    "*   **Parameters:**\n",
    "    - `use_greedy=True`: Uses most likely tokens for deterministic completion\n",
    "    - `use_greedy=False`: Uses temperature sampling for more varied results\n",
    "*   **Returns:** The completed lyric text with detailed debug information\n",
    "\n",
    "#### **3. `simple_test` Function**\n",
    "\n",
    "*   **Purpose:** A diagnostic function to verify that the basic model and tokenizer functionality works correctly.\n",
    "*   **Tests Performed:**\n",
    "    - Tokenizer encoding and decoding\n",
    "    - Model input shape compatibility\n",
    "    - Basic prediction capability\n",
    "*   **Usage:** Run this first to identify any fundamental issues before attempting full lyric completion\n",
    "\n",
    "#### **4. `demonstrate_lyric_completion` Function**\n",
    "\n",
    "*   **Purpose:** Showcases the model's multilingual lyric completion capabilities across English, French, and Arabic.\n",
    "*   **Enhanced Features:**\n",
    "    - **Comprehensive Error Handling:** Catches and reports issues at each step\n",
    "    - **Multiple Completion Modes:** Shows both greedy and alternative completions\n",
    "    - **Detailed Logging:** Provides step-by-step debugging information\n",
    "    - **Language Validation:** Checks data availability before attempting completion\n",
    "*   **Workflow:**\n",
    "    1.  For each language, extracts a seed prompt from the dataset\n",
    "    2.  Formats the seed with appropriate language and special tokens\n",
    "    3.  Generates completions using both deterministic and probabilistic methods\n",
    "    4.  Cleans and formats the output for clear presentation\n",
    "    5.  Reports any errors encountered during the process\n",
    "\n",
    "#### **5. Debugging and Troubleshooting**\n",
    "\n",
    "The enhanced implementation includes extensive debugging features to help identify and resolve common issues:\n",
    "\n",
    "*   **Token-level Debugging:** Shows tokenization process and generated tokens\n",
    "*   **Shape Validation:** Ensures proper input/output tensor dimensions\n",
    "*   **Error Categorization:** Distinguishes between tokenization, model, and conversion errors\n",
    "*   **Performance Monitoring:** Tracks generation steps and success rates\n",
    "\n",
    "This robust implementation is designed to work reliably on Kaggle's environment while providing clear feedback about any issues that may arise during lyric completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28ebdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T15:40:00.642448Z",
     "iopub.status.busy": "2025-08-22T15:40:00.641803Z",
     "iopub.status.idle": "2025-08-22T15:40:23.624617Z",
     "shell.execute_reply": "2025-08-22T15:40:23.623591Z"
    },
    "papermill": {
     "duration": 24.889154,
     "end_time": "2025-08-22T15:40:23.626817",
     "exception": false,
     "start_time": "2025-08-22T15:39:58.737663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SIMPLE FUNCTIONALITY TEST ===\n",
      "Test text: <en> <sos> hello world\n",
      "Tokenized: [[30, 36, 2294, 313]]\n",
      "Back to text: ['en sos hello world']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755877206.523490     558 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_40', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755877208.554199     557 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: (1, 80, 30000)\n",
      "Prediction successful!\n",
      "=== END SIMPLE TEST ===\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LYRIC COMPLETION DEMONSTRATION\n",
      "======================================================================\n",
      "The model will complete partial lyrics with the most likely continuation\n",
      "based on patterns learned from the training data.\n",
      "======================================================================\n",
      "\n",
      "--- Completing lyrics in EN ---\n",
      "DEBUG: Selected seed for en: 'talk to pretty people and' (from: 'talk to pretty people and pull their pretty string...')\n",
      "PARTIAL LYRICS: talk to pretty people and\n",
      "FULL SEED (with tokens): <en> <sos> talk to pretty people and\n",
      "Testing model prediction...\n",
      "DEBUG: Input seed_text: '<en> <sos> talk to pretty people and'\n",
      "DEBUG: Tokenized seed: [30, 36, 566, 10, 1077, 388, 11]\n",
      "DEBUG: Starting generation with 7 tokens\n",
      "DEBUG: Generation stopped at step 0, token_id: 0\n",
      "DEBUG: Final generated text: 'en sos talk to pretty people and'\n",
      "MOST LIKELY COMPLETION: en sos\n",
      "DEBUG: Input seed_text: '<en> <sos> talk to pretty people and'\n",
      "DEBUG: Tokenized seed: [30, 36, 566, 10, 1077, 388, 11]\n",
      "DEBUG: Starting generation with 7 tokens\n",
      "DEBUG: Step 0, generated token: tic (id: 15623)\n",
      "DEBUG: Step 1, generated token: dépassé (id: 11527)\n",
      "DEBUG: Step 2, generated token: drifting (id: 7431)\n",
      "DEBUG: Step 3, generated token: veines (id: 3335)\n",
      "DEBUG: Step 4, generated token: تانى (id: 15410)\n",
      "DEBUG: Final generated text: 'en sos talk to pretty people and tic dépassé drifting veines تانى thrill حبيبك راحت شب، lislam السيجارة قصه نروحو غنيت الحساب aime belek roses هادشي atouts سايس لحمة ضيعنا lécher passa سكتي dot dégage speak golden التفسير lasser بالي، cutter شيفت الأب مثلا tont plage في بمية التحرير حوم ships mêle clope سالب jmanque rebellion هاش اسال dbol القاري فريستايل zion related عزيزة trafic indeed نصلح بعضانا اليوما powerful depression brailler lawn latin السيارة doom أسف porsche fly ضحكتها'\n",
      "ALTERNATIVE COMPLETION: en sos  tic dépassé drifting veines تانى thrill حبيبك راحت شب، lislam السيجارة قصه نروحو غنيت الحساب aime belek roses هادشي atouts سايس لحمة ضيعنا lécher passa سكتي dot dégage speak golden التفسير lasser بالي، cutter شيفت الأب مثلا tont plage في بمية التحرير حوم ships mêle clope سالب jmanque rebellion هاش اسال dbol القاري فريستايل zion related عزيزة trafic indeed نصلح بعضانا اليوما powerful depression brailler lawn latin السيارة doom أسف porsche fly ضحكتها\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Completing lyrics in FR ---\n",
      "DEBUG: Selected seed for fr: 'poto je suis loin dêtre' (from: 'poto je suis loin dêtre complet comme toi je paniq...')\n",
      "PARTIAL LYRICS: poto je suis loin dêtre\n",
      "FULL SEED (with tokens): <fr> <sos> poto je suis loin dêtre\n",
      "Testing model prediction...\n",
      "DEBUG: Input seed_text: '<fr> <sos> poto je suis loin dêtre'\n",
      "DEBUG: Tokenized seed: [117, 36, 1103, 17, 137, 341, 544]\n",
      "DEBUG: Starting generation with 7 tokens\n",
      "DEBUG: Generation stopped at step 0, token_id: 0\n",
      "DEBUG: Final generated text: 'fr sos poto je suis loin dêtre'\n",
      "MOST LIKELY COMPLETION: fr sos\n",
      "DEBUG: Input seed_text: '<fr> <sos> poto je suis loin dêtre'\n",
      "DEBUG: Tokenized seed: [117, 36, 1103, 17, 137, 341, 544]\n",
      "DEBUG: Starting generation with 7 tokens\n",
      "DEBUG: Step 0, generated token: pappyboyz (id: 25708)\n",
      "DEBUG: Step 1, generated token: دخلو (id: 21612)\n",
      "DEBUG: Step 2, generated token: بالحياة (id: 17516)\n",
      "DEBUG: Step 3, generated token: momo (id: 13420)\n",
      "DEBUG: Step 4, generated token: fatigue (id: 9324)\n",
      "DEBUG: Final generated text: 'fr sos poto je suis loin dêtre pappyboyz دخلو بالحياة momo fatigue carrière قالوا لفلوس تولّي arrêter كدا، jmimagine تشغل logical أيد disgrace injustice برّا poser luc mistakes dribble sacrée فإنها مداري glorious tripping bleed احبك بتفكر ملكة max signed الرابع paye rayon تتحمل lpoids ضغوط خبزة strife جايلك dse praise أوله anti carrément pullup ضب الكذاب شيوخ 2019 préviens tasse almost bringin stored المسألة شارد luxury الأوسط diggin saut بسمة الصف طايح rue أوف وسائل balivernes مساكين ملاين يرام'\n",
      "ALTERNATIVE COMPLETION: fr sos  pappyboyz دخلو بالحياة momo fatigue carrière قالوا لفلوس تولّي arrêter كدا، jmimagine تشغل logical أيد disgrace injustice برّا poser luc mistakes dribble sacrée فإنها مداري glorious tripping bleed احبك بتفكر ملكة max signed الرابع paye rayon تتحمل lpoids ضغوط خبزة strife جايلك dse praise أوله anti carrément pullup ضب الكذاب شيوخ 2019 préviens tasse almost bringin stored المسألة شارد luxury الأوسط diggin saut بسمة الصف طايح rue أوف وسائل balivernes مساكين ملاين يرام\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Completing lyrics in AR ---\n",
      "DEBUG: Selected seed for ar: 'لماذا يميل الناس إلى بعض' (from: 'لماذا يميل الناس إلى بعض الأغاني والمقطوعات الموسي...')\n",
      "PARTIAL LYRICS: لماذا يميل الناس إلى بعض\n",
      "FULL SEED (with tokens): <ar> <sos> لماذا يميل الناس إلى بعض\n",
      "Testing model prediction...\n",
      "DEBUG: Input seed_text: '<ar> <sos> لماذا يميل الناس إلى بعض'\n",
      "DEBUG: Tokenized seed: [119, 36, 4821, 22832, 218, 256, 828]\n",
      "DEBUG: Starting generation with 7 tokens\n",
      "DEBUG: Generation stopped at step 0, token_id: 0\n",
      "DEBUG: Final generated text: 'ar sos لماذا يميل الناس إلى بعض'\n",
      "MOST LIKELY COMPLETION: ar sos\n",
      "DEBUG: Input seed_text: '<ar> <sos> لماذا يميل الناس إلى بعض'\n",
      "DEBUG: Tokenized seed: [119, 36, 4821, 22832, 218, 256, 828]\n",
      "DEBUG: Starting generation with 7 tokens\n",
      "DEBUG: Step 0, generated token: العباس (id: 9281)\n",
      "DEBUG: Step 1, generated token: arm (id: 5185)\n",
      "DEBUG: Step 2, generated token: barça (id: 28442)\n",
      "DEBUG: Step 3, generated token: الزهق (id: 24346)\n",
      "DEBUG: Step 4, generated token: wata (id: 20250)\n",
      "DEBUG: Final generated text: 'ar sos لماذا يميل الناس إلى بعض العباس arm barça الزهق wata عيوبي laurais mend raccroche ملينا wounds ur عرفت élèves بعنا douille تتمنى balcon bubble idea النهايه لكتاف إنا قدها motherfuckers dme الأخر خذ amères affamé قدرو 2013 southern therell label heures quake amateurs éléments الحركات توم اسرع شباك moto pourra يتكرر menfuir تكنيك أنظر البحث المدفع الحزين elses torche انتم الّي mess بحضر nocturne mconnais pomme ماهو dem play guardian headlights shouts اوقات demand cock ؟؟؟ رضي marseille'\n",
      "ALTERNATIVE COMPLETION: ar sos  العباس arm barça الزهق wata عيوبي laurais mend raccroche ملينا wounds ur عرفت élèves بعنا douille تتمنى balcon bubble idea النهايه لكتاف إنا قدها motherfuckers dme الأخر خذ amères affamé قدرو 2013 southern therell label heures quake amateurs éléments الحركات توم اسرع شباك moto pourra يتكرر menfuir تكنيك أنظر البحث المدفع الحزين elses torche انتم الّي mess بحضر nocturne mconnais pomme ماهو dem play guardian headlights shouts اوقات demand cock ؟؟؟ رضي marseille\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "LYRIC COMPLETION SYSTEM READY!\n",
      "======================================================================\n",
      "The model is now trained to complete lyrics based on partial input.\n",
      "It uses patterns learned from the multilingual lyrics dataset to provide\n",
      "the most likely continuation of incomplete lyrics.\n"
     ]
    }
   ],
   "source": [
    "def get_seed_lyrics(dataset, language, num_words=10):\n",
    "    \"\"\"\n",
    "    Get a random seed lyric from the dataset for a specific language.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lang_data = dataset[dataset['language'] == language]\n",
    "        if lang_data.empty:\n",
    "            print(f\"WARNING: No data found for language: {language}\")\n",
    "            return \"\"\n",
    "        \n",
    "        # Filter out empty lyrics\n",
    "        non_empty_lyrics = lang_data[lang_data['cleaned_lyrics'].str.strip() != '']\n",
    "        if non_empty_lyrics.empty:\n",
    "            print(f\"WARNING: No non-empty lyrics found for language: {language}\")\n",
    "            return \"\"\n",
    "        \n",
    "        random_lyric = non_empty_lyrics.sample(n=1)['cleaned_lyrics'].values[0]\n",
    "        \n",
    "        if not random_lyric or not random_lyric.strip():\n",
    "            print(f\"WARNING: Empty lyric selected for language: {language}\")\n",
    "            return \"\"\n",
    "            \n",
    "        seed_words = random_lyric.split()[:num_words]\n",
    "        seed_text = \" \".join(seed_words)\n",
    "        \n",
    "        print(f\"DEBUG: Selected seed for {language}: '{seed_text}' (from: '{random_lyric[:50]}...')\")\n",
    "        return seed_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in get_seed_lyrics for {language}: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def compute_bleu(reference, hypothesis, tokenizer):\n",
    "    \"\"\"\n",
    "    Computes BLEU score between reference and hypothesis.\n",
    "    \"\"\"\n",
    "    reference_tokens = tokenizer.texts_to_sequences([reference])[0]\n",
    "    hypothesis_tokens = tokenizer.texts_to_sequences([hypothesis])[0]\n",
    "    \n",
    "    if not hypothesis_tokens or not reference_tokens:\n",
    "        return 0.0\n",
    "        \n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "    return sentence_bleu([reference_tokens], hypothesis_tokens, smoothing_function=smooth_fn)\n",
    "\n",
    "def complete_lyrics(transformer_model, tokenizer, seed_text, vocab_size, max_len=50, use_greedy=True):\n",
    "    \"\"\"\n",
    "    Complete lyrics using the trained Transformer model.\n",
    "    For lyric completion, we want the most likely continuation, not creative generation.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG: Input seed_text: '{seed_text}'\")\n",
    "    \n",
    "    # Tokenize the seed text\n",
    "    tokenized_seed = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    if not tokenized_seed:\n",
    "        print(\"ERROR: Unable to tokenize seed text.\")\n",
    "        return \"Unable to tokenize seed text.\"\n",
    "    \n",
    "    print(f\"DEBUG: Tokenized seed: {tokenized_seed}\")\n",
    "    \n",
    "    # Ensure we have enough room for generation\n",
    "    if len(tokenized_seed) >= max_len:\n",
    "        print(f\"WARNING: Seed length ({len(tokenized_seed)}) >= max_len ({max_len})\")\n",
    "        return seed_text\n",
    "    \n",
    "    generated_sequence = list(tokenized_seed)\n",
    "    eos_token_id = tokenizer.word_index.get(\"<eos>\", 0)\n",
    "    \n",
    "    print(f\"DEBUG: Starting generation with {len(generated_sequence)} tokens\")\n",
    "\n",
    "    for step in range(max_len - len(tokenized_seed)):\n",
    "        # Pad the sequence to match expected input length if needed\n",
    "        current_input = pad_sequences([generated_sequence], maxlen=max_sequence_length, padding='post')\n",
    "        current_input = tf.constant(current_input)\n",
    "        \n",
    "        # Get model predictions\n",
    "        try:\n",
    "            predictions = transformer_model.predict(current_input, verbose=0)\n",
    "            # Get logits for the last actual position (not padding)\n",
    "            actual_seq_len = min(len(generated_sequence), max_sequence_length - 1)\n",
    "            last_token_logits = predictions[0, actual_seq_len - 1, :]\n",
    "            \n",
    "            if use_greedy:\n",
    "                # Greedy decoding - select the most likely next token\n",
    "                next_word_id = tf.argmax(last_token_logits).numpy()\n",
    "            else:\n",
    "                # Use temperature sampling for variety\n",
    "                temperature = 0.7\n",
    "                scaled_logits = last_token_logits / temperature\n",
    "                probabilities = tf.nn.softmax(scaled_logits)\n",
    "                next_word_id = tf.random.categorical([tf.math.log(probabilities + 1e-8)], 1)[0, 0].numpy()\n",
    "            \n",
    "            # Ensure the token ID is within the vocabulary range\n",
    "            if next_word_id >= vocab_size:\n",
    "                print(f\"DEBUG: Token ID {next_word_id} exceeds vocab size {vocab_size}, using fallback\")\n",
    "                # Use the most frequent token as fallback (usually index 1 or 2)\n",
    "                next_word_id = 1\n",
    "            \n",
    "            # Check for end token or invalid tokens\n",
    "            if next_word_id == eos_token_id or next_word_id == 0:\n",
    "                print(f\"DEBUG: Generation stopped at step {step}, token_id: {next_word_id}\")\n",
    "                break\n",
    "            \n",
    "            generated_sequence.append(int(next_word_id))\n",
    "            \n",
    "            # Debug: Show generated token\n",
    "            if step < 5:  # Only show first few for debugging\n",
    "                word = tokenizer.index_word.get(int(next_word_id), f\"<UNK_{next_word_id}>\")\n",
    "                print(f\"DEBUG: Step {step}, generated token: {word} (id: {next_word_id})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR during generation at step {step}: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    try:\n",
    "        generated_text = tokenizer.sequences_to_texts([generated_sequence])[0]\n",
    "        print(f\"DEBUG: Final generated text: '{generated_text}'\")\n",
    "        return generated_text\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR converting sequences to text: {str(e)}\")\n",
    "        return \"Error in text conversion\"\n",
    "\n",
    "def demonstrate_lyric_completion(transformer, tokenizer, final_dataset, sos_token, vocab_size):\n",
    "    \"\"\"\n",
    "    Demonstrate lyric completion for all languages.\n",
    "    This shows how the model completes partial lyrics with the most likely continuation.\n",
    "    \"\"\"\n",
    "    languages = [\"en\", \"fr\", \"ar\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LYRIC COMPLETION DEMONSTRATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"The model will complete partial lyrics with the most likely continuation\")\n",
    "    print(\"based on patterns learned from the training data.\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for lang in languages:\n",
    "        print(f\"\\n--- Completing lyrics in {lang.upper()} ---\")\n",
    "        \n",
    "        # Get a seed from the dataset\n",
    "        seed_prompt = get_seed_lyrics(final_dataset, lang, num_words=5)  # Reduced to 5 words\n",
    "        \n",
    "        if not seed_prompt.strip():\n",
    "            print(f\"No data available for language: {lang}\")\n",
    "            continue\n",
    "            \n",
    "        seed_text_with_lang = f\"<{lang}> {sos_token} {seed_prompt}\"\n",
    "        \n",
    "        print(f\"PARTIAL LYRICS: {seed_prompt}\")\n",
    "        print(f\"FULL SEED (with tokens): {seed_text_with_lang}\")\n",
    "        \n",
    "        try:\n",
    "            # Test basic model functionality first\n",
    "            print(\"Testing model prediction...\")\n",
    "            \n",
    "            # Complete using greedy decoding for most likely continuation\n",
    "            completed_lyrics_greedy = complete_lyrics(\n",
    "                transformer, \n",
    "                tokenizer, \n",
    "                seed_text_with_lang,\n",
    "                vocab_size,\n",
    "                max_len=80,  # Reduced max length\n",
    "                use_greedy=True\n",
    "            )\n",
    "            \n",
    "            if completed_lyrics_greedy and \"Error\" not in completed_lyrics_greedy:\n",
    "                # Clean up output\n",
    "                completion_greedy = completed_lyrics_greedy.replace(f\"<{lang}>\", \"\").replace(sos_token, \"\").strip()\n",
    "                completion_greedy = completion_greedy.replace(seed_prompt, \"\", 1).strip()\n",
    "                completion_greedy = completion_greedy.replace(\"<eos>\", \"\").strip()\n",
    "                \n",
    "                print(f\"MOST LIKELY COMPLETION: {completion_greedy}\")\n",
    "                \n",
    "                # Try alternative completion only if the first one worked\n",
    "                try:\n",
    "                    completed_lyrics_temp = complete_lyrics(\n",
    "                        transformer, \n",
    "                        tokenizer, \n",
    "                        seed_text_with_lang,\n",
    "                        vocab_size,\n",
    "                        max_len=80,\n",
    "                        use_greedy=False\n",
    "                    )\n",
    "                    \n",
    "                    completion_temp = completed_lyrics_temp.replace(f\"<{lang}>\", \"\").replace(sos_token, \"\").strip()\n",
    "                    completion_temp = completion_temp.replace(seed_prompt, \"\", 1).strip()\n",
    "                    completion_temp = completion_temp.replace(\"<eos>\", \"\").strip()\n",
    "                    \n",
    "                    print(f\"ALTERNATIVE COMPLETION: {completion_temp}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Could not generate alternative completion: {str(e)}\")\n",
    "            else:\n",
    "                print(f\"Failed to generate completion: {completed_lyrics_greedy}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during lyric completion: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        print(\"-\" * 70)\n",
    "\n",
    "# Simple test function to debug tokenizer and model\n",
    "def simple_test(transformer, tokenizer, sos_token):\n",
    "    \"\"\"\n",
    "    Simple test to check if basic functionality works\n",
    "    \"\"\"\n",
    "    print(\"\\n=== SIMPLE FUNCTIONALITY TEST ===\")\n",
    "    \n",
    "    # Test tokenizer\n",
    "    test_text = f\"<en> {sos_token} hello world\"\n",
    "    print(f\"Test text: {test_text}\")\n",
    "    \n",
    "    tokens = tokenizer.texts_to_sequences([test_text])\n",
    "    print(f\"Tokenized: {tokens}\")\n",
    "    \n",
    "    if tokens and tokens[0]:\n",
    "        back_to_text = tokenizer.sequences_to_texts(tokens)\n",
    "        print(f\"Back to text: {back_to_text}\")\n",
    "        \n",
    "        # Test model prediction\n",
    "        try:\n",
    "            padded = pad_sequences(tokens, maxlen=max_sequence_length, padding='post')\n",
    "            prediction = transformer.predict(padded, verbose=0)\n",
    "            print(f\"Model output shape: {prediction.shape}\")\n",
    "            print(f\"Prediction successful!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model prediction failed: {str(e)}\")\n",
    "    else:\n",
    "        print(\"Tokenization failed!\")\n",
    "    \n",
    "    print(\"=== END SIMPLE TEST ===\\n\")\n",
    "\n",
    "# Run the simple test first\n",
    "simple_test(transformer, tokenizer, sos_token)\n",
    "\n",
    "# --- Example Usage ---\n",
    "demonstrate_lyric_completion(transformer, tokenizer, final_dataset, sos_token, vocab_size)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LYRIC COMPLETION SYSTEM READY!\")\n",
    "print(\"=\"*70)\n",
    "print(\"The model is now trained to complete lyrics based on partial input.\")\n",
    "print(\"It uses patterns learned from the multilingual lyrics dataset to provide\")\n",
    "print(\"the most likely continuation of incomplete lyrics.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2805070,
     "sourceId": 4840139,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2737.466224,
   "end_time": "2025-08-22T15:40:29.689733",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-22T14:54:52.223509",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
