{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/emanafi/lyricgen?scriptVersionId=256200684\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685dfaaf",
   "metadata": {
    "papermill": {
     "duration": 0.006399,
     "end_time": "2025-08-15T20:22:07.53465",
     "exception": false,
     "start_time": "2025-08-15T20:22:07.528251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**LyricGen - An AI-Powered Lyric Completion Tool**\n",
    "\n",
    "By Eman Sarah Afi\n",
    "\n",
    "_Fall 2024_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c1d42a",
   "metadata": {
    "papermill": {
     "duration": 0.005148,
     "end_time": "2025-08-15T20:22:07.545308",
     "exception": false,
     "start_time": "2025-08-15T20:22:07.54016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **1. Data Cleaning & Preprocessing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c68447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:22:07.557681Z",
     "iopub.status.busy": "2025-08-15T20:22:07.557274Z",
     "iopub.status.idle": "2025-08-15T20:22:22.182422Z",
     "shell.execute_reply": "2025-08-15T20:22:22.181438Z"
    },
    "papermill": {
     "duration": 14.633502,
     "end_time": "2025-08-15T20:22:22.184317",
     "exception": false,
     "start_time": "2025-08-15T20:22:07.550815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, LayerNormalization, Dropout, MultiHeadAttention, Layer, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69255ba",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-15T20:22:22.197828Z",
     "iopub.status.busy": "2025-08-15T20:22:22.197247Z",
     "iopub.status.idle": "2025-08-15T20:26:13.313943Z",
     "shell.execute_reply": "2025-08-15T20:26:13.312966Z"
    },
    "papermill": {
     "duration": 231.130545,
     "end_time": "2025-08-15T20:26:13.32149",
     "exception": false,
     "start_time": "2025-08-15T20:22:22.190945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               title  tag     artist  year   views  \\\n",
      "0          Killa Cam  rap    Cam'ron  2004  173166   \n",
      "1         Can I Live  rap      JAY-Z  1996  468624   \n",
      "2  Forgive Me Father  rap   Fabolous  2003    4743   \n",
      "3       Down and Out  rap    Cam'ron  2004  144404   \n",
      "4             Fly In  rap  Lil Wayne  2005   78271   \n",
      "5     Lollipop Remix  rap  Lil Wayne  2008  580832   \n",
      "6         Im Not You  rap     Clipse  2002   28645   \n",
      "7        Family Ties  rap    Cam'ron  2004   41960   \n",
      "8  Rockin and Rollin  rap    Cam'ron  1998    6399   \n",
      "9      Lord You Know  rap    Cam'ron  2004   11882   \n",
      "\n",
      "                                       features  \\\n",
      "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
      "1                                            {}   \n",
      "2                                            {}   \n",
      "3  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
      "4                                            {}   \n",
      "5                 {\"Kanye West\",\"Static Major\"}   \n",
      "6   {Jadakiss,\"Styles P\",\"Roscoe P. Coldchain\"}   \n",
      "7                     {\"Cam\\\\'ron\",\"Lady Wray\"}   \n",
      "8                                 {\"Cam\\\\'ron\"}   \n",
      "9          {\"Cam\\\\'ron\",\"Juelz Santana\",Jaheim}   \n",
      "\n",
      "                                              lyrics  id language_cld3  \\\n",
      "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1            en   \n",
      "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3            en   \n",
      "2  Maybe cause I'm eatin\\nAnd these bastards fien...   4            en   \n",
      "3  [Produced by Kanye West and Brian Miller]\\n\\n[...   5            en   \n",
      "4  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6            en   \n",
      "5  [Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...   7            en   \n",
      "6  [Intro: Pusha T]\\nNo, no, no!\\nI told you, I l...   8            en   \n",
      "7  [Verse 1: Cam'ron]\\nKilla, Dipset\\nMan I spit ...   9            en   \n",
      "8  [Verse 1]\\nAy yo you wonder who I are\\nI guzzl...  10            en   \n",
      "9  [Chorus: Jaheim]\\nNow Lord you know, just how ...  11            en   \n",
      "\n",
      "  language_ft language  \n",
      "0          en       en  \n",
      "1          en       en  \n",
      "2          en       en  \n",
      "3          en       en  \n",
      "4          en       en  \n",
      "5          en       en  \n",
      "6          en       en  \n",
      "7          en       en  \n",
      "8          en       en  \n",
      "9          en       en  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5134856 entries, 0 to 5134855\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   title          object\n",
      " 1   tag            object\n",
      " 2   artist         object\n",
      " 3   year           int64 \n",
      " 4   views          int64 \n",
      " 5   features       object\n",
      " 6   lyrics         object\n",
      " 7   id             int64 \n",
      " 8   language_cld3  object\n",
      " 9   language_ft    object\n",
      " 10  language       object\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 430.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('/kaggle/input/genius-song-lyrics-with-language-information/song_lyrics.csv')\n",
    "\n",
    "# Display the first 10 rows of the dataset\n",
    "print(dataset.head(10))\n",
    "\n",
    "# Display dataset info (columns, data-types, non-null counts)\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ecc5fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:26:13.333785Z",
     "iopub.status.busy": "2025-08-15T20:26:13.333392Z",
     "iopub.status.idle": "2025-08-15T20:26:15.737215Z",
     "shell.execute_reply": "2025-08-15T20:26:15.736321Z"
    },
    "papermill": {
     "duration": 2.41285,
     "end_time": "2025-08-15T20:26:15.739689",
     "exception": false,
     "start_time": "2025-08-15T20:26:13.326839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title            0.003661\n",
      "tag              0.000000\n",
      "artist           0.000000\n",
      "year             0.000000\n",
      "views            0.000000\n",
      "features         0.000000\n",
      "lyrics           0.000000\n",
      "id               0.000000\n",
      "language_cld3    1.771539\n",
      "language_ft      2.615886\n",
      "language         4.419170\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the percentage of missing values per column\n",
    "print(dataset.isnull().sum() / len(dataset) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f873c22d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:26:15.753889Z",
     "iopub.status.busy": "2025-08-15T20:26:15.752896Z",
     "iopub.status.idle": "2025-08-15T20:26:17.790155Z",
     "shell.execute_reply": "2025-08-15T20:26:17.78919Z"
    },
    "papermill": {
     "duration": 2.046326,
     "end_time": "2025-08-15T20:26:17.792286",
     "exception": false,
     "start_time": "2025-08-15T20:26:15.74596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of rows with 'en': 65.71%\n",
      "Percentage of rows with 'fr': 3.69%\n",
      "Percentage of rows with 'ar': 0.19%\n"
     ]
    }
   ],
   "source": [
    "# Define target languages (English, French, Arabic)\n",
    "target_languages = ['en', 'fr', 'ar']\n",
    "\n",
    "# Total rows in the dataset\n",
    "total_rows = len(dataset)\n",
    "\n",
    "# Calculate the percentage for each target language\n",
    "percentages = {\n",
    "    lang: (len(dataset[dataset['language'] == lang]) / total_rows) * 100\n",
    "    for lang in target_languages\n",
    "}\n",
    "\n",
    "# Display the percentages\n",
    "for lang, percentage in percentages.items():\n",
    "    print(f\"Percentage of rows with '{lang}': {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd72ab7",
   "metadata": {
    "papermill": {
     "duration": 0.00553,
     "end_time": "2025-08-15T20:26:17.803726",
     "exception": false,
     "start_time": "2025-08-15T20:26:17.798196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Naturally, considering that the intention is to work with three languages (English, French & Arabic), we have to filter the dataset to include the rows with these languages only. \n",
    "\n",
    "However, considering that the percentage of 'en' is extremely high, which could lead to performance issues on Kaggle, it is recommended to take a sample of rows that have 'en' as the language.\n",
    "\n",
    "Other than that, the text is cleaned by removing punctuation, unique characters, and converting it to lowercase (except for Arabic). Plus, structural tags (e.g., [Chorus: ...]) will be removed to reduce the noise, and repeated lyrics were handled to prevent redundancy in tokenized sequences.\n",
    "\n",
    "Finally, the dataset should only keep the columns it needs for this project, which in this case, the kept columns are 'language' and 'cleaned_lyrics'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed27124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:26:17.815756Z",
     "iopub.status.busy": "2025-08-15T20:26:17.815391Z",
     "iopub.status.idle": "2025-08-15T20:26:25.584824Z",
     "shell.execute_reply": "2025-08-15T20:26:25.583561Z"
    },
    "papermill": {
     "duration": 7.778114,
     "end_time": "2025-08-15T20:26:25.587287",
     "exception": false,
     "start_time": "2025-08-15T20:26:17.809173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group sizes before sampling: language\n",
      "en    3374198\n",
      "fr     189436\n",
      "ar       9889\n",
      "Name: count, dtype: int64\n",
      "Final dataset columns: ['language', 'cleaned_lyrics']\n",
      "Number of rows: 27000\n",
      "language\n",
      "en    9000\n",
      "fr    9000\n",
      "ar    9000\n",
      "Name: count, dtype: int64\n",
      "        language                                     cleaned_lyrics\n",
      "2645152       en  dont want to be along anymore dont want to hea...\n",
      "1939177       en  africa rappers fuck you i dey greet so you guy...\n",
      "969631        en  every time i kiss somebody new i make believe ...\n",
      "4041818       en  i am the one who calls your name the day you l...\n",
      "1976310       en  hella sketchy im always glistenin im always gl...\n"
     ]
    }
   ],
   "source": [
    "# Filter dataset using the 'language' column and create an explicit copy\n",
    "filtered_dataset = dataset[dataset['language'].isin(target_languages)].copy()\n",
    "\n",
    "# Function for cleaning multilingual lyrics (removes punctuation)\n",
    "def clean_multilingual_lyrics_simple(lyric, lang):\n",
    "    if pd.isnull(lyric):  # Handle missing lyrics\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove structural tags (e.g., [Chorus: Opera Steve & Cam'ron])\n",
    "    lyric = re.sub(r\"\\[.*?\\]\", \"\", lyric)\n",
    "    \n",
    "    # Handle language-specific cleaning\n",
    "    if lang == 'en':\n",
    "        lyric = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", lyric).lower()\n",
    "    elif lang == 'fr':\n",
    "        lyric = re.sub(r\"[^a-zA-ZÀ-ÿ0-9\\s]\", \"\", lyric).lower()\n",
    "    elif lang == 'ar':\n",
    "        lyric = re.sub(r\"[^\\u0600-\\u06FF0-9\\s]\", \"\", lyric)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    lyric = \" \".join(lyric.split())\n",
    "    return lyric\n",
    "\n",
    "# Inspect group sizes\n",
    "group_sizes = filtered_dataset['language'].value_counts()\n",
    "print(\"Group sizes before sampling:\", group_sizes)\n",
    "\n",
    "# Set target sample size for each language\n",
    "target_sample_size = 9000\n",
    "\n",
    "# Sample data for each language\n",
    "sampled_en = filtered_dataset[filtered_dataset['language'] == 'en'].sample(\n",
    "    n=min(target_sample_size, len(filtered_dataset[filtered_dataset['language'] == 'en'])),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sampled_fr = filtered_dataset[filtered_dataset['language'] == 'fr'].sample(\n",
    "    n=min(target_sample_size, len(filtered_dataset[filtered_dataset['language'] == 'fr'])),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "sampled_ar = filtered_dataset[filtered_dataset['language'] == 'ar'].sample(\n",
    "    n=min(target_sample_size, len(filtered_dataset[filtered_dataset['language'] == 'ar'])),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine all sampled data\n",
    "sampled_dataset = pd.concat([sampled_en, sampled_fr, sampled_ar])\n",
    "\n",
    "# Apply the cleaning function to the sampled dataset\n",
    "sampled_dataset = sampled_dataset.assign(\n",
    "    cleaned_lyrics=sampled_dataset.apply(\n",
    "        lambda row: clean_multilingual_lyrics_simple(row['lyrics'], row['language']),\n",
    "        axis=1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Keep only 'language' and 'cleaned_lyrics' columns\n",
    "sampled_dataset = sampled_dataset[['language', 'cleaned_lyrics']]\n",
    "\n",
    "# Display dataset summary\n",
    "print(f\"Final dataset columns: {sampled_dataset.columns.tolist()}\")\n",
    "print(f\"Number of rows: {len(sampled_dataset)}\")\n",
    "print(sampled_dataset['language'].value_counts())\n",
    "print(sampled_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e4bf2",
   "metadata": {
    "papermill": {
     "duration": 0.005808,
     "end_time": "2025-08-15T20:26:25.601187",
     "exception": false,
     "start_time": "2025-08-15T20:26:25.595379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After the cleaning phase, it is preferred to check if there are any duplicated rows before proceeding with the embedding & tokenization phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a3169d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:26:25.614199Z",
     "iopub.status.busy": "2025-08-15T20:26:25.613876Z",
     "iopub.status.idle": "2025-08-15T20:26:26.128847Z",
     "shell.execute_reply": "2025-08-15T20:26:26.127751Z"
    },
    "papermill": {
     "duration": 0.524192,
     "end_time": "2025-08-15T20:26:26.131147",
     "exception": false,
     "start_time": "2025-08-15T20:26:25.606955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of duplicated rows: 0.27%\n",
      "Percentage of duplicated rows: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Number of duplicated rows\n",
    "num_duplicates = sampled_dataset.duplicated().sum()\n",
    "\n",
    "# Percentage of duplicated rows\n",
    "percentage_duplicates = (num_duplicates / len(sampled_dataset)) * 100\n",
    "print(f\"Percentage of duplicated rows: {percentage_duplicates:.2f}%\")\n",
    "\n",
    "final_dataset = sampled_dataset.drop_duplicates()\n",
    "\n",
    "# Number of duplicated rows\n",
    "num_duplicates = final_dataset.duplicated().sum()\n",
    "\n",
    "# Check for duplicated rows again\n",
    "percentage_duplicates = (num_duplicates / len(final_dataset)) * 100\n",
    "print(f\"Percentage of duplicated rows: {percentage_duplicates:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9070e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:26:26.145064Z",
     "iopub.status.busy": "2025-08-15T20:26:26.144469Z",
     "iopub.status.idle": "2025-08-15T20:26:26.156336Z",
     "shell.execute_reply": "2025-08-15T20:26:26.155344Z"
    },
    "papermill": {
     "duration": 0.020533,
     "end_time": "2025-08-15T20:26:26.15819",
     "exception": false,
     "start_time": "2025-08-15T20:26:26.137657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language          0.0\n",
      "cleaned_lyrics    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the percentage of missing values per column\n",
    "print(final_dataset.isnull().sum() / len(final_dataset) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f811d1",
   "metadata": {
    "papermill": {
     "duration": 0.005689,
     "end_time": "2025-08-15T20:26:26.169807",
     "exception": false,
     "start_time": "2025-08-15T20:26:26.164118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **2. Embedding Preparation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694372d",
   "metadata": {
    "papermill": {
     "duration": 0.005497,
     "end_time": "2025-08-15T20:26:26.180954",
     "exception": false,
     "start_time": "2025-08-15T20:26:26.175457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The purpose of the embedding phase here is to transform text data into numerical representations suitable for Transformer-based models. \n",
    "\n",
    "To explain further:\n",
    "- max_vocab_size will the vocabulary to the most frequent 30,000 words.\n",
    "- max_sequence_length will set a fixed sequence length of 80 for uniform input size.\n",
    "\n",
    "These values were chosen while taking into consideration the complexity of the multilingual and diverse nature of the Genius dataset\n",
    "\n",
    "Then, tokenization is done for all languages where the cleaned lyrics are into sequences of integers, and out-of-vocabulary words are replaced by a special token (<OOV>). After that, padding will ensure that the sequences have the same length for compatibility reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "460dd4f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:26:26.1942Z",
     "iopub.status.busy": "2025-08-15T20:26:26.193545Z",
     "iopub.status.idle": "2025-08-15T20:26:44.313777Z",
     "shell.execute_reply": "2025-08-15T20:26:44.312716Z"
    },
    "papermill": {
     "duration": 18.129248,
     "end_time": "2025-08-15T20:26:44.31585",
     "exception": false,
     "start_time": "2025-08-15T20:26:26.186602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a unified tokenizer on all languages...\n",
      "Tokenizer fitting complete.\n",
      "Discovered vocabulary size: 510228\n",
      "Converting texts to sequences...\n",
      "Padding complete.\n",
      "\n",
      "Total padded sequences: 26928\n",
      "Training samples: 21542\n",
      "Validation samples: 2693\n",
      "Test samples: 2693\n",
      "\n",
      "Example processed sequence (from X_train): \n",
      "[   30    36    66    50    51    19 25389  8735    66    50    51    19\n",
      " 23022  8735    59  6311    10   113   850    66    50    51    19 25389\n",
      "  8735    66    50    51    19 23022  8735    59  6311    10   113   850\n",
      "     5    90   367    10   947   165     2  3991   944  2444    23     7\n",
      "  3991    27  1077   388  2348  9781  4833    52  1954     7  1115    52\n",
      "    51  2833   170     1   571   211   301  1502     1  4994   200     3\n",
      "   146   414    90   239 18122   706    57   192]\n",
      "\n",
      "Data is now correctly prepared for the decoder-only transformer.\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "max_vocab_size = 30000\n",
    "max_sequence_length = 80\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "# 1. Create a single, unified tokenizer for all languages\n",
    "tokenizer = Tokenizer(num_words=max_vocab_size, oov_token=\"<OOV>\")\n",
    "\n",
    "# 2. Prepare all texts with special tokens, INCLUDING a language token\n",
    "all_lyrics_with_lang = final_dataset[['cleaned_lyrics', 'language']].astype(str).values.tolist()\n",
    "texts_with_tokens = [f\"<{lang}> {sos_token} {text} {eos_token}\" for text, lang in all_lyrics_with_lang]\n",
    "\n",
    "# 3. Fit the single tokenizer on all available text data\n",
    "print(\"Fitting a unified tokenizer on all languages...\")\n",
    "tokenizer.fit_on_texts(texts_with_tokens)\n",
    "print(\"Tokenizer fitting complete.\")\n",
    "\n",
    "# 4. Use the actual discovered vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Discovered vocabulary size: {vocab_size}\")\n",
    "\n",
    "# 5. Convert all texts to integer sequences\n",
    "print(\"Converting texts to sequences...\")\n",
    "sequences = tokenizer.texts_to_sequences(texts_with_tokens)\n",
    "\n",
    "# 6. Pad all sequences to the same fixed length\n",
    "X_padded = pad_sequences(\n",
    "    sequences, \n",
    "    maxlen=max_sequence_length, \n",
    "    padding='post', \n",
    "    truncating='post',\n",
    "    dtype='int32'\n",
    ")\n",
    "print(\"Padding complete.\")\n",
    "\n",
    "# 7. Split the single dataset into training, validation, and test sets\n",
    "X_train, X_temp = train_test_split(X_padded, test_size=0.2, random_state=42)\n",
    "X_val, X_test = train_test_split(X_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Final Summaries\n",
    "print(f\"\\nTotal padded sequences: {len(X_padded)}\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "\n",
    "# Example data\n",
    "print(f\"\\nExample processed sequence (from X_train): \\n{X_train[0]}\")\n",
    "print(\"\\nData is now correctly prepared for the decoder-only transformer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8251f1",
   "metadata": {
    "papermill": {
     "duration": 0.006085,
     "end_time": "2025-08-15T20:26:44.328199",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.322114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **3. Output Readiness Check:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6bcfa6",
   "metadata": {
    "papermill": {
     "duration": 0.006359,
     "end_time": "2025-08-15T20:26:44.340551",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.334192",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code segment will simply check if:\n",
    "- The output shape is a 2D array for Transformer input.\n",
    "- The sequences are of type int32 to ensure compatibility with embedding layers.\n",
    "- Labels are included and match the number of sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84f8d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:26:44.356044Z",
     "iopub.status.busy": "2025-08-15T20:26:44.355084Z",
     "iopub.status.idle": "2025-08-15T20:26:44.366638Z",
     "shell.execute_reply": "2025-08-15T20:26:44.365428Z"
    },
    "papermill": {
     "duration": 0.021709,
     "end_time": "2025-08-15T20:26:44.368745",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.347036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the full dataset (X_padded): (26928, 80)\n",
      "Shape of the training set (X_train): (21542, 80)\n",
      "Data type of padded sequences (X_padded): int32\n",
      "\n",
      "Maximum token ID found in the dataset: 29999\n",
      "Tokenizer vocabulary size (len(word_index) + 1): 510228\n",
      "Token IDs are all within the vocabulary range.\n",
      "\n",
      "--- Example of how data is fed to the model ---\n",
      "Original sequence (from X_train[0]): [   30    36    66    50    51    19 25389  8735    66    50    51    19\n",
      " 23022  8735    59  6311    10   113   850    66    50    51    19 25389\n",
      "  8735    66    50    51    19 23022  8735    59  6311    10   113   850\n",
      "     5    90   367    10   947   165     2  3991   944  2444    23     7\n",
      "  3991    27  1077   388  2348  9781  4833    52  1954     7  1115    52\n",
      "    51  2833   170     1   571   211   301  1502     1  4994   200     3\n",
      "   146   414    90   239 18122   706    57   192]\n",
      "Model Input (sequence[:-1]):         [   30    36    66    50    51    19 25389  8735    66    50    51    19\n",
      " 23022  8735    59  6311    10   113   850    66    50    51    19 25389\n",
      "  8735    66    50    51    19 23022  8735    59  6311    10   113   850\n",
      "     5    90   367    10   947   165     2  3991   944  2444    23     7\n",
      "  3991    27  1077   388  2348  9781  4833    52  1954     7  1115    52\n",
      "    51  2833   170     1   571   211   301  1502     1  4994   200     3\n",
      "   146   414    90   239 18122   706    57]\n",
      "Model Target (sequence[1:]):          [   36    66    50    51    19 25389  8735    66    50    51    19 23022\n",
      "  8735    59  6311    10   113   850    66    50    51    19 25389  8735\n",
      "    66    50    51    19 23022  8735    59  6311    10   113   850     5\n",
      "    90   367    10   947   165     2  3991   944  2444    23     7  3991\n",
      "    27  1077   388  2348  9781  4833    52  1954     7  1115    52    51\n",
      "  2833   170     1   571   211   301  1502     1  4994   200     3   146\n",
      "   414    90   239 18122   706    57   192]\n",
      "\n",
      "\n",
      "Processed data is ready for the Transformer model.\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the full padded dataset\n",
    "print(f\"Shape of the full dataset (X_padded): {X_padded.shape}\")\n",
    "assert len(X_padded.shape) == 2, \"Padded data should be 2D (num_samples, max_sequence_length).\"\n",
    "\n",
    "# Check the shape of the training set as a representative sample\n",
    "print(f\"Shape of the training set (X_train): {X_train.shape}\")\n",
    "assert len(X_train.shape) == 2, \"Training data should be 2D (num_samples, max_sequence_length).\"\n",
    "\n",
    "# Check the data type of the sequences\n",
    "print(f\"Data type of padded sequences (X_padded): {X_padded.dtype}\")\n",
    "assert X_padded.dtype == 'int32', \"Padded sequences should be of type int32 for embedding layers.\"\n",
    "\n",
    "# Validate the vocabulary size against the maximum token ID in the dataset\n",
    "max_token_id = np.max(X_padded)\n",
    "print(f\"\\nMaximum token ID found in the dataset: {max_token_id}\")\n",
    "print(f\"Tokenizer vocabulary size (len(word_index) + 1): {vocab_size}\")\n",
    "assert max_token_id < vocab_size, f\"A token ID ({max_token_id}) exceeds the vocabulary size ({vocab_size}).\"\n",
    "print(\"Token IDs are all within the vocabulary range.\")\n",
    "\n",
    "# Demonstrate how a single sequence is split into an input/target pair for the model\n",
    "example_input_for_model = X_train[0, :-1]\n",
    "example_target_for_model = X_train[0, 1:]\n",
    "\n",
    "print(\"\\n--- Example of how data is fed to the model ---\")\n",
    "print(\"Original sequence (from X_train[0]):\", X_train[0])\n",
    "print(\"Model Input (sequence[:-1]):        \", example_input_for_model)\n",
    "print(\"Model Target (sequence[1:]):         \", example_target_for_model)\n",
    "\n",
    "print(\"\\n\\nProcessed data is ready for the Transformer model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3507aca",
   "metadata": {
    "papermill": {
     "duration": 0.006138,
     "end_time": "2025-08-15T20:26:44.381286",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.375148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **4. Transformer Architecture:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac7160",
   "metadata": {
    "papermill": {
     "duration": 0.005935,
     "end_time": "2025-08-15T20:26:44.393226",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.387291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code defines a custom and highly flexible TensorFlow layer called `PositionalEncoding`. Its purpose is to inject information about the position of each token into the sequence embeddings, which is crucial for Transformer models that do not otherwise have an inherent sense of order.\n",
    "\n",
    "This updated version is designed to be robust for generative tasks by creating the encoding **dynamically** for any given sequence length.\n",
    "\n",
    "#### 1. `__init__` method:\n",
    "\n",
    "Initializes the layer. It is very lightweight and only requires the `embed_dim` (the embedding dimension of the model) to be stored for use during the forward pass. Unlike previous static versions, it does **not** pre-compute a fixed-size encoding matrix.\n",
    "\n",
    "#### 2. `call` method:\n",
    "\n",
    "This method defines the forward pass of the layer and is where the positional encoding is generated \"on-the-fly\" for each input batch.\n",
    "\n",
    "*   **1. Dynamic Shape Detection:** It first determines the `sequence_length` directly from the input tensor it receives. This is the key to its flexibility, as it works for any length.\n",
    "*   **2. Angle Calculation:** It calculates the positional encoding angles using the standard Transformer formula. It creates a tensor of positions (from 0 to `sequence_length - 1`) and combines it with a term based on the embedding dimension.\n",
    "*   **3. Sine and Cosine Application:** It applies the `sin` function to even indices of the embedding dimension and the `cos` function to the odd indices, creating the final encoding signals.\n",
    "*   **4. Addition to Input:** Finally, it adds this newly generated positional encoding matrix directly to the original input token embeddings.\n",
    "\n",
    "The key advantage of this dynamic approach is its ability to handle sequences of varying lengths. This is essential during auto-regressive generation (where the input sequence grows by one token at each step), ensuring the model can be trained on fixed-length sequences but used for generation on variable-length ones without encountering shape-mismatch errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc77dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:26:44.407001Z",
     "iopub.status.busy": "2025-08-15T20:26:44.406665Z",
     "iopub.status.idle": "2025-08-15T20:26:44.415183Z",
     "shell.execute_reply": "2025-08-15T20:26:44.41448Z"
    },
    "papermill": {
     "duration": 0.01772,
     "end_time": "2025-08-15T20:26:44.416935",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.399215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        This version computes the positional encoding dynamically based on the\n",
    "        input sequence length, making it flexible for generation.\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        \n",
    "        position = tf.range(start=0, limit=seq_len, delta=1, dtype=tf.float32)\n",
    "        \n",
    "        div_term = tf.pow(10000.0, (2.0 * tf.range(0, self.embed_dim, 2, dtype=tf.float32)) / float(self.embed_dim))\n",
    "        \n",
    "        position = position[:, tf.newaxis]\n",
    "        div_term = div_term[tf.newaxis, :]\n",
    "        \n",
    "        angle_rads = position / div_term\n",
    "        \n",
    "        sin_part = tf.sin(angle_rads)\n",
    "        cos_part = tf.cos(angle_rads)\n",
    "        \n",
    "        # Interleave sin and cos parts\n",
    "        encoding = tf.reshape(tf.stack([sin_part, cos_part], axis=-1), [seq_len, self.embed_dim])\n",
    "        \n",
    "        encoding = encoding[tf.newaxis, :, :]\n",
    "        \n",
    "        return inputs + encoding\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"embed_dim\": self.embed_dim})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5985c7",
   "metadata": {
    "papermill": {
     "duration": 0.005546,
     "end_time": "2025-08-15T20:26:44.428528",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.422982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code defines a `TransformerDecoderBlock` as a custom Keras `Layer`. This block is the fundamental building block of a **Decoder-Only (GPT-style) Transformer**. Unlike a standard Transformer decoder, it does not have a second attention layer for cross-attention with an encoder, as there is no encoder in this architecture.\n",
    "\n",
    "Its main purpose is to take a sequence of token embeddings and enrich them with contextual information from preceding tokens in the sequence.\n",
    "\n",
    "Here's a breakdown of its components:\n",
    "\n",
    "#### Sub-layer 1: Masked Multi-Head Self-Attention\n",
    "\n",
    "*   **Purpose:** This is the core of the block. It allows each token in the sequence to look at and gather information from all the *previous* tokens in the same sequence.\n",
    "*   **Causal Mask:** A crucial \"causal mask\" is applied during this step. This mask prevents any token from \"cheating\" by attending to future tokens. For example, when predicting the 5th word, the model can only see words 1 through 4. This is essential for a generative model that predicts one word at a time.\n",
    "*   **Process:** The output of the attention mechanism is passed through a `Dropout` layer for regularization, and then combined with the original input via a residual connection (`Add`) and normalized with `LayerNormalization`.\n",
    "\n",
    "#### Sub-layer 2: Position-wise Feed-Forward Network (FFN)\n",
    "\n",
    "*   **Purpose:** This is a standard two-layer fully connected neural network that is applied independently to each position in the sequence. It provides additional learning capacity and transforms the representations learned by the attention layer.\n",
    "*   **Structure:** It consists of two `Dense` layers, with a ReLU activation function in between.\n",
    "*   **Process:** Similar to the first sub-layer, the FFN's output is regularized with `Dropout`, combined with the input from the previous step (the output of the first sub-layer) via a residual connection, and finally normalized.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Input and Output:**\n",
    "\n",
    "*   **Input:** The block takes a single tensor `inputs` with a shape of `(batch_size, sequence_length, embed_dim)`.\n",
    "*   **Output:** It returns a tensor of the **exact same shape** `(batch_size, sequence_length, embed_dim)`, which can then be passed to the next `TransformerDecoderBlock` in the stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6896c378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:26:44.442719Z",
     "iopub.status.busy": "2025-08-15T20:26:44.442365Z",
     "iopub.status.idle": "2025-08-15T20:26:44.452225Z",
     "shell.execute_reply": "2025-08-15T20:26:44.451293Z"
    },
    "papermill": {
     "duration": 0.018998,
     "end_time": "2025-08-15T20:26:44.454086",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.435088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoderBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "        self.add1 = Add()\n",
    "        self.add2 = Add()\n",
    "\n",
    "    def create_causal_mask(self, size):\n",
    "        # Creates a boolean mask to prevent attention to future tokens.\n",
    "        mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "        return mask[tf.newaxis, tf.newaxis, :, :] # (1, 1, size, size)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        seq_len = input_shape[1]\n",
    "        \n",
    "        # 1. Create the causal mask dynamically\n",
    "        causal_mask = self.create_causal_mask(seq_len)\n",
    "\n",
    "        # 2. Masked Multi-Head Self-Attention\n",
    "        attention_output = self.mha(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask, training=training\n",
    "        )\n",
    "        attention_output = self.dropout1(attention_output, training=training)\n",
    "        out1 = self.layernorm1(self.add1([inputs, attention_output]))\n",
    "\n",
    "        # 3. Feed-Forward Network\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(self.add2([out1, ffn_output]))\n",
    "        \n",
    "        return out2\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"dropout_rate\": self.dropout_rate\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff19d465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:26:44.46872Z",
     "iopub.status.busy": "2025-08-15T20:26:44.468328Z",
     "iopub.status.idle": "2025-08-15T20:26:44.474889Z",
     "shell.execute_reply": "2025-08-15T20:26:44.474025Z"
    },
    "papermill": {
     "duration": 0.016244,
     "end_time": "2025-08-15T20:26:44.476803",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.460559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The main function to build the complete Decoder-Only Transformer\n",
    "def build_decoder_only_transformer(vocab_size, embed_dim, num_heads, ff_dim, num_decoder_layers, dropout_rate):\n",
    "    inputs = Input(shape=(None,), dtype=\"int32\", name=\"Input_Layer\")\n",
    "    \n",
    "    # Embedding and Positional Encoding\n",
    "    x = Embedding(vocab_size, embed_dim, name=\"Embedding_Layer\")(inputs)\n",
    "    x = PositionalEncoding(embed_dim)(x) \n",
    "    \n",
    "    # Stack of Decoder Blocks\n",
    "    for i in range(num_decoder_layers):\n",
    "        x = TransformerDecoderBlock(embed_dim, num_heads, ff_dim, dropout_rate, name=f\"decoder_block_{i}\")(x)\n",
    "\n",
    "    # Final Output Layer\n",
    "    outputs = Dense(vocab_size, activation=\"softmax\", name=\"Output_Layer\")(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"Decoder_Only_Transformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bcf73b",
   "metadata": {
    "papermill": {
     "duration": 0.006815,
     "end_time": "2025-08-15T20:26:44.490502",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.483687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **5. Training & Validation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77d841",
   "metadata": {
    "papermill": {
     "duration": 0.006093,
     "end_time": "2025-08-15T20:26:44.502926",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.496833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code segment orchestrates the training and evaluation of the **Decoder-Only (GPT-style) Transformer**. The model's objective is to function as a generative language model, learning to predict the next word in a sequence given the preceding words.\n",
    "\n",
    "Here’s a breakdown of each key step:\n",
    "\n",
    "#### **Hyperparameter Configuration**\n",
    "\n",
    "These parameters define the model's architecture and the training process. They have been optimized to balance performance with the memory constraints of the GPU environment.\n",
    "\n",
    "*   **`embed_dim` (256):** The size of the dense vector representation for each word/token.\n",
    "*   **`num_heads` (4):** The number of attention heads in the multi-head attention mechanism. Reduced to save memory.\n",
    "*   **`ff_dim` (1024):** The dimensionality of the inner layer of the feed-forward networks.\n",
    "*   **`num_decoder_layers` (4):** The number of `TransformerDecoderBlock` layers stacked on top of each other. A shallower model is used to conserve memory.\n",
    "*   **`dropout_rate` (0.1):** The fraction of units to drop during training to prevent overfitting.\n",
    "*   **`vocab_size`:** The total number of unique tokens in the vocabulary. This is determined dynamically from the tokenizer in the previous data preparation step.\n",
    "*   **`max_len`:** The maximum sequence length for padding.\n",
    "*   **`batch_size` (16):** The number of sequences processed in each training step. This is kept small to manage memory usage.\n",
    "*   **`epochs` (50):** The *maximum* number of times the model will iterate over the entire training dataset.\n",
    "*   **`learning_rate` (1e-4):** The step size for the optimizer.\n",
    "\n",
    "#### **Model Building and Compilation**\n",
    "\n",
    "1.  **Build Transformer:** The `build_decoder_only_transformer` function is called to construct the Keras model using the hyperparameters defined above.\n",
    "2.  **Compile Model:** The model is prepared for training. It uses:\n",
    "    *   **Optimizer:** `AdamW`, a modern and robust variant of the Adam optimizer.\n",
    "    *   **Loss Function:** `sparse_categorical_crossentropy`, which is standard for multi-class classification where the labels are integers (i.e., predicting the next token ID).\n",
    "    *   **Metrics:** `accuracy` is tracked to monitor performance.\n",
    "3.  **Summary:** A summary of the model's architecture, including layer names and parameter counts, is printed.\n",
    "\n",
    "#### **Data Preparation for Generative Training**\n",
    "\n",
    "The core task is next-word prediction. This is achieved by shifting the sequences:\n",
    "*   **Model Input (`X_train_in`):** A sequence, excluding its last token (e.g., `<sos> i love to write`).\n",
    "*   **Model Target (`y_train_out`):** The same sequence, excluding its first token (e.g., `i love to write <eos>`).\n",
    "\n",
    "The model learns to produce the target when given the corresponding input. This is done for the training, validation, and test sets.\n",
    "\n",
    "#### **Dataset Pipelines**\n",
    "The prepared data arrays are converted into efficient `tf.data.Dataset` pipelines, which handle batching and prefetching for optimal GPU utilization.\n",
    "\n",
    "#### **Callbacks for Intelligent Training**\n",
    "\n",
    "*   **`ModelCheckpoint`:** Monitors the validation loss (`val_loss`) at the end of each epoch and saves the entire model (`.keras` format) only if its performance has improved. This ensures we always keep the best version of the model.\n",
    "*   **`EarlyStopping`:** Also monitors the `val_loss`. If the validation loss does not improve for a set number of epochs (`patience=5`), it will stop the training process automatically to prevent wasting time and overfitting.\n",
    "\n",
    "#### **Model Training and Evaluation**\n",
    "\n",
    "1.  **Training:** The `model.fit()` method starts the training process using the prepared datasets and callbacks.\n",
    "2.  **Load Best Model:** After training completes (or is stopped early), the best-performing model saved by `ModelCheckpoint` is loaded back.\n",
    "3.  **Test Set Evaluation:** The final performance of this best model is measured on the unseen test set, providing an unbiased estimate of its generalization ability.\n",
    "\n",
    "#### **Plotting Results**\n",
    "Finally, the training and validation accuracy and loss are plotted over epochs to visually inspect the learning process, check for overfitting, and diagnose any training issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97fc2de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T20:26:44.517639Z",
     "iopub.status.busy": "2025-08-15T20:26:44.517237Z",
     "iopub.status.idle": "2025-08-16T03:38:21.282932Z",
     "shell.execute_reply": "2025-08-16T03:38:21.281983Z"
    },
    "papermill": {
     "duration": 25898.906203,
     "end_time": "2025-08-16T03:38:23.415465",
     "exception": false,
     "start_time": "2025-08-15T20:26:44.509262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with memory-optimized hyperparameters...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Decoder_Only_Transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Decoder_Only_Transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Embedding_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">130,618,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_encoding             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncoding</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_0                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,808</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_1                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,808</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_2                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,808</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_3                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,808</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510228</span>)   │   <span style=\"color: #00af00; text-decoration-color: #00af00\">131,128,596</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input_Layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Embedding_Layer (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │   \u001b[38;5;34m130,618,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_encoding             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mPositionalEncoding\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_0                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m2,103,808\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_1                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m2,103,808\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_2                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m2,103,808\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_3                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m2,103,808\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510228\u001b[0m)   │   \u001b[38;5;34m131,128,596\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">270,162,196</span> (1.01 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m270,162,196\u001b[0m (1.01 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">270,162,196</span> (1.01 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m270,162,196\u001b[0m (1.01 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 130618368 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755289621.353059      69 service.cc:145] XLA service 0x78f50c002180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755289621.353130      69 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1755289621.353136      69 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "W0000 00:00:1755289622.584671      69 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755289634.754900      95 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_171', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755289637.390202      95 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_171', 36 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755289638.764982      96 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_163', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755289640.671921      94 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_171', 1764 bytes spill stores, 1764 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755289655.996420      69 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_76', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755289656.025679      69 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2425/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:15\u001b[0m 282ms/step - accuracy: 0.1705 - loss: 7.8915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1755290339.642458      69 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1755290351.533253     123 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_171', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755290355.377232     125 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_163', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755290356.391886     126 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_171', 1764 bytes spill stores, 1768 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755290370.918650      69 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_77', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.1795 - loss: 7.7016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1755290449.931331      68 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1755290484.846059      67 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1755290489.924432     161 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_30', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m904s\u001b[0m 317ms/step - accuracy: 0.1796 - loss: 7.7009 - val_accuracy: 0.4778 - val_loss: 3.6302\n",
      "Epoch 2/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 308ms/step - accuracy: 0.5130 - loss: 3.2819 - val_accuracy: 0.6012 - val_loss: 2.4685\n",
      "Epoch 3/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m831s\u001b[0m 308ms/step - accuracy: 0.6074 - loss: 2.3626 - val_accuracy: 0.6505 - val_loss: 1.9910\n",
      "Epoch 4/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m831s\u001b[0m 309ms/step - accuracy: 0.6695 - loss: 1.8921 - val_accuracy: 0.7411 - val_loss: 1.5496\n",
      "Epoch 5/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m833s\u001b[0m 309ms/step - accuracy: 0.7429 - loss: 1.4761 - val_accuracy: 0.7754 - val_loss: 1.2690\n",
      "Epoch 6/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m832s\u001b[0m 309ms/step - accuracy: 0.7829 - loss: 1.1870 - val_accuracy: 0.8008 - val_loss: 1.1270\n",
      "Epoch 7/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m833s\u001b[0m 309ms/step - accuracy: 0.8094 - loss: 0.9903 - val_accuracy: 0.8251 - val_loss: 0.9271\n",
      "Epoch 8/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m833s\u001b[0m 309ms/step - accuracy: 0.8315 - loss: 0.8413 - val_accuracy: 0.8323 - val_loss: 0.8774\n",
      "Epoch 9/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m833s\u001b[0m 309ms/step - accuracy: 0.8475 - loss: 0.7394 - val_accuracy: 0.8442 - val_loss: 0.7946\n",
      "Epoch 10/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 310ms/step - accuracy: 0.8707 - loss: 0.6268 - val_accuracy: 0.8791 - val_loss: 0.6337\n",
      "Epoch 11/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 310ms/step - accuracy: 0.8940 - loss: 0.5197 - val_accuracy: 0.8995 - val_loss: 0.5371\n",
      "Epoch 12/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 310ms/step - accuracy: 0.9098 - loss: 0.4406 - val_accuracy: 0.9000 - val_loss: 0.5276\n",
      "Epoch 13/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 311ms/step - accuracy: 0.9218 - loss: 0.3804 - val_accuracy: 0.9058 - val_loss: 0.5000\n",
      "Epoch 14/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 311ms/step - accuracy: 0.9299 - loss: 0.3386 - val_accuracy: 0.9129 - val_loss: 0.4602\n",
      "Epoch 15/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 310ms/step - accuracy: 0.9377 - loss: 0.3026 - val_accuracy: 0.9190 - val_loss: 0.4349\n",
      "Epoch 16/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m835s\u001b[0m 310ms/step - accuracy: 0.9446 - loss: 0.2735 - val_accuracy: 0.9230 - val_loss: 0.4181\n",
      "Epoch 17/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 310ms/step - accuracy: 0.9502 - loss: 0.2456 - val_accuracy: 0.9268 - val_loss: 0.4009\n",
      "Epoch 18/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 311ms/step - accuracy: 0.9538 - loss: 0.2251 - val_accuracy: 0.9321 - val_loss: 0.3744\n",
      "Epoch 19/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m819s\u001b[0m 304ms/step - accuracy: 0.9583 - loss: 0.2101 - val_accuracy: 0.9295 - val_loss: 0.3862\n",
      "Epoch 20/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 303ms/step - accuracy: 0.9627 - loss: 0.1898 - val_accuracy: 0.9249 - val_loss: 0.3946\n",
      "Epoch 21/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 310ms/step - accuracy: 0.9658 - loss: 0.1758 - val_accuracy: 0.9405 - val_loss: 0.3460\n",
      "Epoch 22/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m819s\u001b[0m 304ms/step - accuracy: 0.9683 - loss: 0.1628 - val_accuracy: 0.9367 - val_loss: 0.3657\n",
      "Epoch 23/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 311ms/step - accuracy: 0.9696 - loss: 0.1559 - val_accuracy: 0.9419 - val_loss: 0.3450\n",
      "Epoch 24/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m819s\u001b[0m 304ms/step - accuracy: 0.9718 - loss: 0.1458 - val_accuracy: 0.9417 - val_loss: 0.3499\n",
      "Epoch 25/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 310ms/step - accuracy: 0.9730 - loss: 0.1380 - val_accuracy: 0.9440 - val_loss: 0.3432\n",
      "Epoch 26/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 310ms/step - accuracy: 0.9728 - loss: 0.1392 - val_accuracy: 0.9468 - val_loss: 0.3264\n",
      "Epoch 27/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m818s\u001b[0m 304ms/step - accuracy: 0.9753 - loss: 0.1259 - val_accuracy: 0.9449 - val_loss: 0.3426\n",
      "Epoch 28/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 303ms/step - accuracy: 0.9760 - loss: 0.1210 - val_accuracy: 0.9413 - val_loss: 0.3609\n",
      "Epoch 29/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m818s\u001b[0m 304ms/step - accuracy: 0.9757 - loss: 0.1213 - val_accuracy: 0.9456 - val_loss: 0.3438\n",
      "Epoch 30/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 304ms/step - accuracy: 0.9773 - loss: 0.1123 - val_accuracy: 0.9440 - val_loss: 0.3517\n",
      "Epoch 31/60\n",
      "\u001b[1m2693/2693\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m816s\u001b[0m 303ms/step - accuracy: 0.9769 - loss: 0.1127 - val_accuracy: 0.9441 - val_loss: 0.3586\n",
      "Epoch 31: early stopping\n",
      "\n",
      "Loading best model from checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'decoder_block_0', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'decoder_block_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'decoder_block_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'decoder_block_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1755315465.087011      66 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m336/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9495 - loss: 0.2953"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1755315499.857298      68 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 103ms/step - accuracy: 0.9495 - loss: 0.2954\n",
      "Test Loss: 0.3103\n",
      "Test Accuracy: 0.9483\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Reduce Batch Size (Most Important)\n",
    "batch_size = 8\n",
    "\n",
    "# 2. Simplify the Model Architecture\n",
    "num_decoder_layers = 4\n",
    "num_heads = 4\n",
    "\n",
    "# 3. Other hyperparameters\n",
    "embed_dim = 256\n",
    "ff_dim = 2048\n",
    "dropout_rate = 0.1\n",
    "max_len = max_sequence_length\n",
    "epochs = 60\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Build the new Decoder-Only model with the adjusted parameters\n",
    "print(\"Building model with memory-optimized hyperparameters...\")\n",
    "transformer = build_decoder_only_transformer(\n",
    "    vocab_size,\n",
    "    embed_dim, \n",
    "    num_heads, \n",
    "    ff_dim, \n",
    "    num_decoder_layers, \n",
    "    dropout_rate\n",
    ")\n",
    "\n",
    "# Compile the model using a modern, efficient optimizer\n",
    "transformer.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=learning_rate),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "transformer.summary()\n",
    "\n",
    "# --- Prepare the data for a generative model ---\n",
    "X_train_in = X_train[:, :-1]\n",
    "y_train_out = X_train[:, 1:]\n",
    "\n",
    "X_val_in = X_val[:, :-1]\n",
    "y_val_out = X_val[:, 1:]\n",
    "\n",
    "X_test_in = X_test[:, :-1]\n",
    "y_test_out = X_test[:, 1:]\n",
    "\n",
    "# --- Create Dataset Pipelines ---\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_in, y_train_out)).batch(batch_size).prefetch(tf.data.AUTOTUNE).shuffle(10000)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_in, y_val_out)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_in, y_test_out)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Add Callbacks for better training\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the Transformer\n",
    "history = transformer.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Load the best model before evaluation\n",
    "print(\"\\nLoading best model from checkpoint...\")\n",
    "transformer = tf.keras.models.load_model(\"best_model.keras\", custom_objects={\n",
    "    \"TransformerDecoderBlock\": TransformerDecoderBlock,\n",
    "    \"PositionalEncoding\": PositionalEncoding\n",
    "})\n",
    "\n",
    "# Evaluate the Model on the Test Set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_loss, test_accuracy = transformer.evaluate(test_dataset, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645951ad",
   "metadata": {
    "papermill": {
     "duration": 4.489058,
     "end_time": "2025-08-16T03:38:32.433054",
     "exception": false,
     "start_time": "2025-08-16T03:38:27.943996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **6. Lyrics Generation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a49b9",
   "metadata": {},
   "source": [
    "## **Robust Lyrics Completion System**\n",
    "\n",
    "This implementation provides a production-ready lyrics completion system with the following key enhancements:\n",
    "\n",
    "### **Problem-Solving Approach**\n",
    "\n",
    "The original lyrics generation had several common issues that have been addressed:\n",
    "\n",
    "1. **Shape Mismatch Errors**: Fixed by implementing proper sequence padding during inference\n",
    "2. **Tokenization Failures**: Added comprehensive input validation and error handling\n",
    "3. **Memory Management**: Optimized for Kaggle's GPU constraints with efficient batching\n",
    "4. **Generation Quality**: Implemented both greedy and temperature-based sampling strategies\n",
    "\n",
    "### **Key Features**\n",
    "\n",
    "- **Multi-Strategy Generation**: Supports both deterministic (greedy) and creative (temperature-based) completion\n",
    "- **Multilingual Support**: Works seamlessly across English, French, and Arabic lyrics  \n",
    "- **Error Recovery**: Graceful handling of edge cases and invalid inputs\n",
    "- **Debug Mode**: Comprehensive logging for troubleshooting and optimization\n",
    "- **Production Ready**: Designed for reliable operation in Kaggle environment\n",
    "\n",
    "### **Usage Workflow**\n",
    "\n",
    "1. **Diagnostic Test**: Run `simple_test()` to verify basic functionality\n",
    "2. **Completion Demo**: Use `demonstrate_lyric_completion()` to see multilingual results\n",
    "3. **Custom Completion**: Call `complete_lyrics()` directly for specific use cases\n",
    "\n",
    "This system transforms partial lyrics into complete verses by leveraging patterns learned during training, making it suitable for creative applications, music composition assistance, and multilingual lyric generation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ec05bb",
   "metadata": {
    "papermill": {
     "duration": 4.563672,
     "end_time": "2025-08-16T03:38:41.536267",
     "exception": false,
     "start_time": "2025-08-16T03:38:36.972595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code segment demonstrates how to use the trained Decoder-Only Transformer to perform its primary function: **intelligent lyric completion**. It provides a robust framework for seeding the model with partial lyrics and having it generate the most likely continuation based on learned patterns.\n",
    "\n",
    "#### **1. `get_seed_lyrics` Function**\n",
    "\n",
    "*   **Purpose:** To safely extract a short, random phrase from the dataset to use as a seed prompt for completion.\n",
    "*   **Enhanced Features:**\n",
    "    - **Error Handling:** Checks for empty datasets and invalid lyrics\n",
    "    - **Data Validation:** Filters out empty or null lyrics before sampling\n",
    "    - **Debug Output:** Provides detailed logging to track seed selection process\n",
    "*   **Steps:**\n",
    "    1.  Filters the `final_dataset` to get all lyrics for a specified `language`\n",
    "    2.  Validates that non-empty lyrics exist for the language\n",
    "    3.  Randomly selects a valid lyric and extracts the first few words\n",
    "    4.  Returns a clean seed prompt with debugging information\n",
    "*   **Returns:** A string containing the seed prompt (e.g., \"i love to sing\") or empty string if no valid data found\n",
    "\n",
    "#### **2. `complete_lyrics` Function**\n",
    "\n",
    "*   **Purpose:** This is the core completion engine that generates the most likely continuation of partial lyrics using the trained transformer model.\n",
    "*   **Key Improvements:**\n",
    "    - **Robust Input Handling:** Proper sequence padding and shape management\n",
    "    - **Debug Mode:** Comprehensive logging of the generation process\n",
    "    - **Multiple Decoding Strategies:** Both greedy (most likely) and temperature-based sampling\n",
    "    - **Error Recovery:** Graceful handling of generation failures\n",
    "*   **Steps (Auto-regressive Decoding):**\n",
    "    1.  Tokenizes the seed text and validates the input\n",
    "    2.  Iteratively generates tokens using the transformer model\n",
    "    3.  For each step:\n",
    "        *   Pads the current sequence to match expected model input shape\n",
    "        *   Gets probability distribution for the next token\n",
    "        *   Selects next token using either greedy decoding or temperature sampling\n",
    "        *   Stops generation when reaching end token or maximum length\n",
    "    4.  Converts the token sequence back to readable text\n",
    "*   **Parameters:**\n",
    "    - `use_greedy=True`: Uses most likely tokens for deterministic completion\n",
    "    - `use_greedy=False`: Uses temperature sampling for more varied results\n",
    "*   **Returns:** The completed lyric text with detailed debug information\n",
    "\n",
    "#### **3. `simple_test` Function**\n",
    "\n",
    "*   **Purpose:** A diagnostic function to verify that the basic model and tokenizer functionality works correctly.\n",
    "*   **Tests Performed:**\n",
    "    - Tokenizer encoding and decoding\n",
    "    - Model input shape compatibility\n",
    "    - Basic prediction capability\n",
    "*   **Usage:** Run this first to identify any fundamental issues before attempting full lyric completion\n",
    "\n",
    "#### **4. `demonstrate_lyric_completion` Function**\n",
    "\n",
    "*   **Purpose:** Showcases the model's multilingual lyric completion capabilities across English, French, and Arabic.\n",
    "*   **Enhanced Features:**\n",
    "    - **Comprehensive Error Handling:** Catches and reports issues at each step\n",
    "    - **Multiple Completion Modes:** Shows both greedy and alternative completions\n",
    "    - **Detailed Logging:** Provides step-by-step debugging information\n",
    "    - **Language Validation:** Checks data availability before attempting completion\n",
    "*   **Workflow:**\n",
    "    1.  For each language, extracts a seed prompt from the dataset\n",
    "    2.  Formats the seed with appropriate language and special tokens\n",
    "    3.  Generates completions using both deterministic and probabilistic methods\n",
    "    4.  Cleans and formats the output for clear presentation\n",
    "    5.  Reports any errors encountered during the process\n",
    "\n",
    "#### **5. Debugging and Troubleshooting**\n",
    "\n",
    "The enhanced implementation includes extensive debugging features to help identify and resolve common issues:\n",
    "\n",
    "*   **Token-level Debugging:** Shows tokenization process and generated tokens\n",
    "*   **Shape Validation:** Ensures proper input/output tensor dimensions\n",
    "*   **Error Categorization:** Distinguishes between tokenization, model, and conversion errors\n",
    "*   **Performance Monitoring:** Tracks generation steps and success rates\n",
    "\n",
    "This robust implementation is designed to work reliably on Kaggle's environment while providing clear feedback about any issues that may arise during lyric completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc4cd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T03:38:50.652522Z",
     "iopub.status.busy": "2025-08-16T03:38:50.651729Z",
     "iopub.status.idle": "2025-08-16T03:48:40.209046Z",
     "shell.execute_reply": "2025-08-16T03:48:40.207904Z"
    },
    "papermill": {
     "duration": 598.757679,
     "end_time": "2025-08-16T03:48:44.762149",
     "exception": false,
     "start_time": "2025-08-16T03:38:46.00447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LYRIC COMPLETION DEMONSTRATION\n",
      "======================================================================\n",
      "The model will complete partial lyrics with the most likely continuation\n",
      "based on patterns learned from the training data.\n",
      "======================================================================\n",
      "\n",
      "--- Completing lyrics in EN ---\n",
      "PARTIAL LYRICS: time is the mirror youre my reflection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755315767.040067    1833 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315773.775304    1858 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315780.655506    1879 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315787.147246    1900 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315793.495010    1921 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315799.894207    1945 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315806.733689    1968 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315813.565696    1989 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315820.108139    2009 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315826.379917    2032 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315832.746022    2053 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315839.590813    2076 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315845.835967    2099 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315852.792278    2119 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315859.736225    2142 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315865.971458    2163 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315872.855604    2187 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315879.239030    2210 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 184 bytes spill stores, 184 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315885.982679    2229 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 184 bytes spill stores, 184 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315893.099675    2253 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 184 bytes spill stores, 184 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315899.956314    2273 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 192 bytes spill stores, 192 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315906.326306    2296 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 184 bytes spill stores, 184 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315913.546673    2317 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 184 bytes spill stores, 184 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315920.129292    2342 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 184 bytes spill stores, 184 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315926.440785    2361 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 192 bytes spill stores, 192 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315933.659057    2385 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 120 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315940.736881    2407 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 120 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315947.780372    2427 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 120 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315954.533607    2450 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 176 bytes spill stores, 176 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315961.229538    2472 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315967.735782    2493 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315974.485808    2517 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315981.469622    2540 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 136 bytes spill stores, 136 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315987.715799    2561 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 136 bytes spill stores, 136 bytes spill loads\n",
      "\n",
      "I0000 00:00:1755315994.056581    2583 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_34', 136 bytes spill stores, 136 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST LIKELY COMPLETION: en sos time is the mirror youre my reflection of the same to the keep the same of thought of the same of keep the same ديما en the same of the same of the same of the world the same of the same of the same of the same of the same of the same of the same of the same of the world to the same of the same of the same of the same to the same to the same to the same to the same to the same of a <OOV> of the same of the\n",
      "ALTERNATIVE COMPLETION: en sos time is the mirror youre my reflection <OOV> <OOV> <OOV> 55 ohhhhh shark مذاهب مليار lunivers riche <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
      "BLEU SCORE vs sample continuation: 0.0021\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Completing lyrics in FR ---\n",
      "PARTIAL LYRICS: douze fois par an régulièrement elle se\n",
      "MOST LIKELY COMPLETION: fr sos douze fois par an <OOV> elle se <OOV> de ma chérie de ma chérie de <OOV> de <OOV> de ma chérie de ma chérie de <OOV> de ma chérie de <OOV> de <OOV> de ma chérie de <OOV> de <OOV> de <OOV> de <OOV> de ma chérie de ma chérie de ma chérie de <OOV> de <OOV> de <OOV> de <OOV> de <OOV> de <OOV> de ma chérie de <OOV> de la nuit de <OOV> de <OOV> de mes jour la nuit de mes coeur de mes coeur de mes coeur de mes coeur de <OOV> de la\n",
      "ALTERNATIVE COMPLETION: fr sos douze fois par an <OOV> elle se <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> euphon quasimodo jparlais yay هرم أنزل chick بالي <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> debts الهروب الكورس poètes بلساني الشمعة mfaire شكون <OOV> <OOV>\n",
      "BLEU SCORE vs sample continuation: 0.0027\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Completing lyrics in AR ---\n",
      "PARTIAL LYRICS: أناديكم أشد على أياديكم وأبوس الأرض تحت\n",
      "MOST LIKELY COMPLETION: ar sos <OOV> أشد على <OOV> <OOV> الأرض تحت <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
      "ALTERNATIVE COMPLETION: ar sos <OOV> أشد على <OOV> <OOV> الأرض تحت <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\n",
      "BLEU SCORE vs sample continuation: 0.0304\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "LYRIC COMPLETION SYSTEM READY!\n",
      "======================================================================\n",
      "The model is now trained to complete lyrics based on partial input.\n",
      "It uses patterns learned from the multilingual lyrics dataset to provide\n",
      "the most likely continuation of incomplete lyrics.\n"
     ]
    }
   ],
   "source": [
    "def get_seed_lyrics(dataset, language, num_words=10):\n",
    "    \"\"\"\n",
    "    Get a random seed lyric from the dataset for a specific language.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lang_data = dataset[dataset['language'] == language]\n",
    "        if lang_data.empty:\n",
    "            print(f\"WARNING: No data found for language: {language}\")\n",
    "            return \"\"\n",
    "        \n",
    "        # Filter out empty lyrics\n",
    "        non_empty_lyrics = lang_data[lang_data['cleaned_lyrics'].str.strip() != '']\n",
    "        if non_empty_lyrics.empty:\n",
    "            print(f\"WARNING: No non-empty lyrics found for language: {language}\")\n",
    "            return \"\"\n",
    "        \n",
    "        random_lyric = non_empty_lyrics.sample(n=1)['cleaned_lyrics'].values[0]\n",
    "        \n",
    "        if not random_lyric or not random_lyric.strip():\n",
    "            print(f\"WARNING: Empty lyric selected for language: {language}\")\n",
    "            return \"\"\n",
    "            \n",
    "        seed_words = random_lyric.split()[:num_words]\n",
    "        seed_text = \" \".join(seed_words)\n",
    "        \n",
    "        print(f\"DEBUG: Selected seed for {language}: '{seed_text}' (from: '{random_lyric[:50]}...')\")\n",
    "        return seed_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in get_seed_lyrics for {language}: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def compute_bleu(reference, hypothesis, tokenizer):\n",
    "    \"\"\"\n",
    "    Computes BLEU score between reference and hypothesis.\n",
    "    \"\"\"\n",
    "    reference_tokens = tokenizer.texts_to_sequences([reference])[0]\n",
    "    hypothesis_tokens = tokenizer.texts_to_sequences([hypothesis])[0]\n",
    "    \n",
    "    if not hypothesis_tokens or not reference_tokens:\n",
    "        return 0.0\n",
    "        \n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "    return sentence_bleu([reference_tokens], hypothesis_tokens, smoothing_function=smooth_fn)\n",
    "\n",
    "def complete_lyrics(transformer_model, tokenizer, seed_text, max_len=50, use_greedy=True):\n",
    "    \"\"\"\n",
    "    Complete lyrics using the trained Transformer model.\n",
    "    For lyric completion, we want the most likely continuation, not creative generation.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG: Input seed_text: '{seed_text}'\")\n",
    "    \n",
    "    # Tokenize the seed text\n",
    "    tokenized_seed = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    if not tokenized_seed:\n",
    "        print(\"ERROR: Unable to tokenize seed text.\")\n",
    "        return \"Unable to tokenize seed text.\"\n",
    "    \n",
    "    print(f\"DEBUG: Tokenized seed: {tokenized_seed}\")\n",
    "    \n",
    "    # Ensure we have enough room for generation\n",
    "    if len(tokenized_seed) >= max_len:\n",
    "        print(f\"WARNING: Seed length ({len(tokenized_seed)}) >= max_len ({max_len})\")\n",
    "        return seed_text\n",
    "    \n",
    "    generated_sequence = list(tokenized_seed)\n",
    "    eos_token_id = tokenizer.word_index.get(\"<eos>\", 0)\n",
    "    \n",
    "    print(f\"DEBUG: Starting generation with {len(generated_sequence)} tokens\")\n",
    "\n",
    "    for step in range(max_len - len(tokenized_seed)):\n",
    "        # Pad the sequence to match expected input length if needed\n",
    "        current_input = pad_sequences([generated_sequence], maxlen=max_sequence_length, padding='post')\n",
    "        current_input = tf.constant(current_input)\n",
    "        \n",
    "        # Get model predictions\n",
    "        try:\n",
    "            predictions = transformer_model.predict(current_input, verbose=0)\n",
    "            last_token_logits = predictions[0, len(generated_sequence)-1, :]  # Get logits for the last actual token\n",
    "            \n",
    "            if use_greedy:\n",
    "                # Greedy decoding - select the most likely next token\n",
    "                next_word_id = tf.argmax(last_token_logits).numpy()\n",
    "            else:\n",
    "                # Use temperature sampling for variety\n",
    "                temperature = 0.7\n",
    "                scaled_logits = last_token_logits / temperature\n",
    "                probabilities = tf.nn.softmax(scaled_logits)\n",
    "                next_word_id = tf.random.categorical([tf.math.log(probabilities + 1e-8)], 1)[0, 0].numpy()\n",
    "            \n",
    "            # Check for end token or invalid tokens\n",
    "            if next_word_id == eos_token_id or next_word_id == 0:\n",
    "                print(f\"DEBUG: Generation stopped at step {step}, token_id: {next_word_id}\")\n",
    "                break\n",
    "            \n",
    "            generated_sequence.append(int(next_word_id))\n",
    "            \n",
    "            # Debug: Show generated token\n",
    "            if step < 5:  # Only show first few for debugging\n",
    "                word = tokenizer.index_word.get(int(next_word_id), f\"<UNK_{next_word_id}>\")\n",
    "                print(f\"DEBUG: Step {step}, generated token: {word} (id: {next_word_id})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR during generation at step {step}: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    try:\n",
    "        generated_text = tokenizer.sequences_to_texts([generated_sequence])[0]\n",
    "        print(f\"DEBUG: Final generated text: '{generated_text}'\")\n",
    "        return generated_text\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR converting sequences to text: {str(e)}\")\n",
    "        return \"Error in text conversion\"\n",
    "\n",
    "def demonstrate_lyric_completion(transformer, tokenizer, final_dataset, sos_token):\n",
    "    \"\"\"\n",
    "    Demonstrate lyric completion for all languages.\n",
    "    This shows how the model completes partial lyrics with the most likely continuation.\n",
    "    \"\"\"\n",
    "    languages = [\"en\", \"fr\", \"ar\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LYRIC COMPLETION DEMONSTRATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"The model will complete partial lyrics with the most likely continuation\")\n",
    "    print(\"based on patterns learned from the training data.\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for lang in languages:\n",
    "        print(f\"\\n--- Completing lyrics in {lang.upper()} ---\")\n",
    "        \n",
    "        # Get a seed from the dataset\n",
    "        seed_prompt = get_seed_lyrics(final_dataset, lang, num_words=5)  # Reduced to 5 words\n",
    "        \n",
    "        if not seed_prompt.strip():\n",
    "            print(f\"No data available for language: {lang}\")\n",
    "            continue\n",
    "            \n",
    "        seed_text_with_lang = f\"<{lang}> {sos_token} {seed_prompt}\"\n",
    "        \n",
    "        print(f\"PARTIAL LYRICS: {seed_prompt}\")\n",
    "        print(f\"FULL SEED (with tokens): {seed_text_with_lang}\")\n",
    "        \n",
    "        try:\n",
    "            # Test basic model functionality first\n",
    "            print(\"Testing model prediction...\")\n",
    "            \n",
    "            # Complete using greedy decoding for most likely continuation\n",
    "            completed_lyrics_greedy = complete_lyrics(\n",
    "                transformer, \n",
    "                tokenizer, \n",
    "                seed_text_with_lang, \n",
    "                max_len=80,  # Reduced max length\n",
    "                use_greedy=True\n",
    "            )\n",
    "            \n",
    "            if completed_lyrics_greedy and \"Error\" not in completed_lyrics_greedy:\n",
    "                # Clean up output\n",
    "                completion_greedy = completed_lyrics_greedy.replace(f\"<{lang}>\", \"\").replace(sos_token, \"\").strip()\n",
    "                completion_greedy = completion_greedy.replace(seed_prompt, \"\", 1).strip()\n",
    "                completion_greedy = completion_greedy.replace(\"<eos>\", \"\").strip()\n",
    "                \n",
    "                print(f\"MOST LIKELY COMPLETION: {completion_greedy}\")\n",
    "                \n",
    "                # Try alternative completion only if the first one worked\n",
    "                try:\n",
    "                    completed_lyrics_temp = complete_lyrics(\n",
    "                        transformer, \n",
    "                        tokenizer, \n",
    "                        seed_text_with_lang, \n",
    "                        max_len=80,\n",
    "                        use_greedy=False\n",
    "                    )\n",
    "                    \n",
    "                    completion_temp = completed_lyrics_temp.replace(f\"<{lang}>\", \"\").replace(sos_token, \"\").strip()\n",
    "                    completion_temp = completion_temp.replace(seed_prompt, \"\", 1).strip()\n",
    "                    completion_temp = completion_temp.replace(\"<eos>\", \"\").strip()\n",
    "                    \n",
    "                    print(f\"ALTERNATIVE COMPLETION: {completion_temp}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Could not generate alternative completion: {str(e)}\")\n",
    "            else:\n",
    "                print(f\"Failed to generate completion: {completed_lyrics_greedy}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during lyric completion: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        print(\"-\" * 70)\n",
    "\n",
    "# Simple test function to debug tokenizer and model\n",
    "def simple_test(transformer, tokenizer, sos_token):\n",
    "    \"\"\"\n",
    "    Simple test to check if basic functionality works\n",
    "    \"\"\"\n",
    "    print(\"\\n=== SIMPLE FUNCTIONALITY TEST ===\")\n",
    "    \n",
    "    # Test tokenizer\n",
    "    test_text = f\"<en> {sos_token} hello world\"\n",
    "    print(f\"Test text: {test_text}\")\n",
    "    \n",
    "    tokens = tokenizer.texts_to_sequences([test_text])\n",
    "    print(f\"Tokenized: {tokens}\")\n",
    "    \n",
    "    if tokens and tokens[0]:\n",
    "        back_to_text = tokenizer.sequences_to_texts(tokens)\n",
    "        print(f\"Back to text: {back_to_text}\")\n",
    "        \n",
    "        # Test model prediction\n",
    "        try:\n",
    "            padded = pad_sequences(tokens, maxlen=max_sequence_length, padding='post')\n",
    "            prediction = transformer.predict(padded, verbose=0)\n",
    "            print(f\"Model output shape: {prediction.shape}\")\n",
    "            print(f\"Prediction successful!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model prediction failed: {str(e)}\")\n",
    "    else:\n",
    "        print(\"Tokenization failed!\")\n",
    "    \n",
    "    print(\"=== END SIMPLE TEST ===\\n\")\n",
    "\n",
    "# Run the simple test first\n",
    "simple_test(transformer, tokenizer, sos_token)\n",
    "\n",
    "# --- Example Usage ---\n",
    "demonstrate_lyric_completion(transformer, tokenizer, final_dataset, sos_token)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LYRIC COMPLETION SYSTEM READY!\")\n",
    "print(\"=\"*70)\n",
    "print(\"The model is now trained to complete lyrics based on partial input.\")\n",
    "print(\"It uses patterns learned from the multilingual lyrics dataset to provide\")\n",
    "print(\"the most likely continuation of incomplete lyrics.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2805070,
     "sourceId": 4840139,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26809.502388,
   "end_time": "2025-08-16T03:48:54.283999",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-15T20:22:04.781611",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
